---
title: "Measurement trends in psychology"
subtitle: "Analysis"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# \TODO

- separate models for other DVs or one combined model? if combined, can i do direct comparisons between them?
- add pairwise comparisons for subfields?
- think about priors more
- think about model diagnostics more

```{r setup, include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

```

```{r}

library(dplyr)
library(tidyr)
library(tibble)
library(ggplot2)
library(scales)
library(ggstance)
library(brms)
library(tidybayes)
library(emmeans)
#library(broom)
library(purrr)
library(janitor)
library(knitr)
library(kableExtra)
library(forcats)

```

# Simulate data

We will have two raters and they can either (a) score each article so that each one is scored twice, or (b) they could overlap eg 10% of articles for double scoring, so that more articles can be scored in total. Any input on this?

Each rater will score each measurement type as either present (1) or absent (0) in that article. There are 6 measurement types according to our scoring, and we see these categories as exhaustive. There will probably be 6 subfields and 5 journals per subfield. 

In the case of disagreements, should we solve this in data processing (get agreement between the authors/round down/round up) or model it? 

The total number of articles to be scored is still to be determined, as we don't know the average extraction time or the total resources available to us here (1 or 2 RAs or masters students or a mix).

When a journal has not existed for all years in the range, should we still extract the same number of articles from the years that do exist, or should we extract a proportionate number of articles (so the articles per year is stable)?

```{r}

set.seed(42)

n_articles_per_journal <- 15 # current estimate
n_journals_per_subfield <- 5
n_subfields <- 6

n_articles_total <- n_articles_per_journal * n_journals_per_subfield * n_subfields

data_simulated <-
  tibble(
    article_id = seq(from = 1, 
                     to = n_articles_total, 
                     by = 1),
    year = sample(x = 2009:2023,  # year range 
                  size = n_articles_total, 
                  replace = TRUE),
    uses_self_reports = c(rbinom(n = n_articles_total/2,
                                 size = 1, # values between 0 and 1
                                 prob = .95), # probability of a given study containing such a measure
                          rbinom(n = n_articles_total/2,
                                 size = 1, # values between 0 and 1
                                 prob = .70)),
    uses_direct_behavioral_measures = rbinom(n = n_articles_total,
                                             size = 1, # values between 0 and 1
                                             prob = .05), # probability of a given study containing such a measure
    uses_behavioral_proxy = rbinom(n = n_articles_total,
                                   size = 1, # values between 0 and 1
                                   prob = .1), # probability of a given study containing such a measure
    uses_neuro_bio = rbinom(n = n_articles_total,
                            size = 1, # values between 0 and 1
                            prob = .1), # probability of a given study containing such a measure
    uses_self_reports_about_behaviors = rbinom(n = n_articles_total,
                                               size = 1, # values between 0 and 1
                                               prob = .1), # probability of a given study containing such a measure
    uses_generative_and_ability_tasks = rbinom(n = n_articles_total,
                                               size = 1, # values between 0 and 1
                                               prob = .1) # probability of a given study containing such a measure
  ) |>
  mutate(article_id = as.factor(paste0("doi_", article_id)),
         subfield = c(rep("General", n_articles_per_journal * n_journals_per_subfield),
                      rep("Cognitive", n_articles_per_journal * n_journals_per_subfield),
                      rep("Clinical", n_articles_per_journal * n_journals_per_subfield),
                      rep("Developmental", n_articles_per_journal * n_journals_per_subfield),
                      rep("I/O", n_articles_per_journal * n_journals_per_subfield),
                      rep("Social/Personality", n_articles_per_journal * n_journals_per_subfield)),
         subfield = as.factor(subfield),
         journal = paste(subfield, "journal", seq(from = 1, to = 5)), 6)

```

## Check

```{r}

data_simulated |>
  count(subfield, journal)

data_simulated |>
  summarize(mean_uses_self_reports = mean(uses_self_reports),
            mean_uses_direct_behavioral_measures = mean(uses_direct_behavioral_measures),
            mean_uses_behavioral_proxy = mean(uses_behavioral_proxy)) |>
  mutate_all(round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

data_simulated |>
  group_by(subfield, journal) |>
  summarize(mean_uses_self_reports = mean(uses_self_reports),
            mean_uses_direct_behavioral_measures = mean(uses_direct_behavioral_measures),
            mean_uses_behavioral_proxy = mean(uses_behavioral_proxy)) |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

# Analyze

## Fit model

```{r}

# how to easily produce a prevalence estimate? By centering year before fitting? Solomon will have a fancier brms solution
data_simulated_centered <- data_simulated |>
  #mutate(year_centered = as.numeric(scale(year, center = TRUE, scale = FALSE)))
  mutate(year_centered = year - 2016)

# example model fit
fit_uses_self_reports <-
  brm(uses_self_reports ~ 1 + year_centered + (1 + year_centered | subfield/journal),
      family = bernoulli(link = "logit"),
      data = data_simulated_centered)

# fit_uses_self_reports <- 
#   brm(uses_self_reports ~ 1 + year_centered + (1 | subfield),  
#       family = bernoulli(link = "logit"),
#       data = data_simulated_centered)

fit_uses_direct_behavioral_measures <-
  brm(uses_direct_behavioral_measures ~ 1 + year_centered + (1 + year_centered | subfield/journal),
      family = bernoulli(link = "logit"),
      data = data_simulated_centered)

fit_multivariate <- brm(
  mvbind(uses_self_reports, uses_direct_behavioral_measures) ~ 1 + year_centered + (1 + year_centered | subfield/journal),
  family = bernoulli(link = "logit"),
  data = data_simulated_centered
)

```

## Extract posteriors

https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/

### Prevalence

```{r}

# master vectors
outcome_measures <- c("usesselfreports", "usesdirectbehavioralmeasures")

# subfields <- data_simulated_centered |>
#   distinct(subfield, journal) |>
#   pull(subfield)
# 
# journals <- data_simulated_centered |>
#   filter(subfield == subfield) |>
#   distinct(journal) |>
#   pull(journal)


# extractions
est_prevalence_grandmean <- function(fit, outcome){
  fit |>
    emmeans(specs = ~ 1,
            at = list(year_centered = 0),
            epred = TRUE,
            re_formula = NA,
            allow_new_levels = FALSE,
            resp = outcome) |>
    summary() |>
    mutate(re_level = "field",
           outcome = outcome) |>
    select(re_level,
           prevalence_estimate = emmean,
           prevalence_ci_lower = lower.HPD,
           prevalence_ci_upper = upper.HPD)
}

helper_function_prevalence_grandmean <- function(outcome, fit){
  expand_grid(outcome = outcome) |>
    mutate(res = pmap(list(list(fit),
                           outcome),
                      est_prevalence_grandmean)) |>
    unnest(cols = c(res))
}

res_prevalence_field <- 
  tibble(res = pmap(list(outcome_measures), 
                    helper_function_prevalence_grandmean, 
                    fit = fit_multivariate)) |>
  unnest(res)



# estimate prevalence for either an existing subfield and journal, or an existing subfield and hypothetical journal, or hypothetical subfield and journal
est_prevalence <- function(fit, outcome, subfield, journal, re_level){
  fit |>
    emmeans(specs = ~ 1,
            at = list(year_centered = 0,
                      subfield = subfield,
                      journal = journal),
            resp = outcome,
            epred = TRUE,
            re_formula = NULL,
            allow_new_levels = TRUE,
            sample_new_levels = "uncertainty",
            rg.limit = 40000)  |>
    summary() |>
    mutate(re_level = re_level) |>
    select(re_level,
           prevalence_estimate = emmean,
           prevalence_ci_lower = lower.HPD,
           prevalence_ci_upper = upper.HPD)
}

helper_function_prevalence <- function(subfield, journal, outcome, re_level, fit){
  tibble(subfield = subfield,
         journal = journal) |>
    mutate(res = pmap(list(list(fit),
                           outcome,
                           subfield,
                           journal,
                           re_level),
                      est_prevalence)) |>
    unnest(cols = c(res)) |>
    select(-outcome, -subfield, -journal)
}


res_prevalence_journals <- 
  expand_grid(data_simulated_centered |>
                distinct(subfield, journal),
              outcome = outcome_measures) |>
  mutate(res = pmap(list(subfield, journal, outcome), 
                    helper_function_prevalence, 
                    re_level = "journals", 
                    fit = fit_multivariate)) |>
  unnest()

res_prevalence_subfields <- 
  expand_grid(data_simulated_centered |>
                distinct(subfield),
              journal = "hypothetical typical journal",
              outcome = outcome_measures) |>
  mutate(res = pmap(list(subfield, journal, outcome), 
                    helper_function_prevalence, 
                    re_level = "subfields", 
                    fit = fit_multivariate)) |>
  unnest()


res_prevalence <- 
  bind_rows(res_prevalence_field,
            res_prevalence_subfields,
            res_prevalence_journals) |>
  mutate(label = case_when(re_level == "field" ~ "Psychology",
                           re_level == "subfields" & journal == "hypothetical typical journal" ~ subfield,
                           journal != "hypothetical typical journal" & !is.na(journal) ~ journal)) |>
  mutate(label = fct_relevel(
    label,
    "Psychology", 

    "General", 
    "General journal 2", 
    "General journal 3", 
    "General journal 4", 
    "General journal 5", 
    "General journal 1", 
    
    "Cognitive", 
    "Cognitive journal 2", 
    "Cognitive journal 3", 
    "Cognitive journal 4", 
    "Cognitive journal 5", 
    "Cognitive journal 1", 
    
    "Clinical", 
    "Clinical journal 3", 
    "Clinical journal 4", 
    "Clinical journal 5", 
    "Clinical journal 1", 
    "Clinical journal 2", 
    
    "Developmental", 
    "Developmental journal 4", 
    "Developmental journal 5", 
    "Developmental journal 1", 
    "Developmental journal 2", 
    "Developmental journal 3", 
    
    "I/O", 
    "I/O journal 5", 
    "I/O journal 1", 
    "I/O journal 2", 
    "I/O journal 3", 
    "I/O journal 4", 
    
    "Social/Personality", 
    "Social/Personality journal 1", 
    "Social/Personality journal 2", 
    "Social/Personality journal 3", 
    "Social/Personality journal 4", 
    "Social/Personality journal 5"                   
  ),
  label = fct_rev(label)) |>
  mutate(outcome = case_when(outcome == "usesdirectbehavioralmeasures" ~ "Behavioral measure",
                             outcome == "usesselfreports" ~ "Self-report measure",
                             TRUE ~ outcome)) |>
  select(outcome, label, re_level, subfield, journal, 
         prevalence_estimate, prevalence_ci_lower, prevalence_ci_upper)

# res_prevalence |>
#   distinct(label) |>
#   pull(label) |>
#   dput()

res_prevalence |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)


p_prevalence <- 
  ggplot(res_prevalence, aes(prevalence_estimate, label)) +
  geom_linerangeh(aes(xmin = prevalence_ci_lower, xmax = prevalence_ci_upper)) +
  geom_point() +
  coord_cartesian(xlim = c(0, 1)) +
  theme_linedraw() +
  ylab("") +
  xlab("Prevalence") +
  facet_wrap(~ outcome)

p_prevalence

```

### Trend

\TODO got to here - need to update below to handle multivariate model


```{r}

# grand mean
res_trend_field <- fit_uses_self_reports |>
  emtrends(specs = ~ year_centered,
           var = "year_centered",
           at = list(year_centered = 0),
           epred = TRUE, 
           re_formula = NA, 
           allow_new_levels = FALSE) |>
  summary() |>
  mutate(re_level = "field") |>
  select(re_level,
         trend_estimate = year_centered.trend,
         trend_ci_lower = lower.HPD,
         trend_ci_upper = upper.HPD)

# res_trend_field |>
#   mutate_if(is.numeric, round_half_up, digits = 3)


# # hypothetical typical new group
# res_draws_trend <- fit_uses_self_reports |>
#   emtrends(specs = ~ year_centered,
#            var = "year_centered",
#            at = list(year_centered = 0, 
#                      subfield = "typicalsubfield",
#                      journal = "typicaljournal"),
#            epred = TRUE, 
#            re_formula = NULL, 
#            allow_new_levels = TRUE, 
#            sample_new_levels = "uncertainty") |>
#   summary() |>
#   rename(trend_estimate = year_centered.trend,
#          trend_ci_lower = lower.HPD,
#          trend_ci_upper = upper.HPD)
# 
# res_draws_trend |>
#   mutate_if(is.numeric, round_half_up, digits = 3)


# existing levels of each level and journal
# res_draws_prevalence <- fit_uses_self_reports |>
#   emtrends(specs = ~ year_centered,
#            var = "year_centered",
#            at = list(year_centered = 0,
#                      subfield = "sf_4",
#                      journal = "j_19"), 
#            epred = TRUE, 
#            re_formula = NULL, 
#            allow_new_levels = FALSE) |>
#   summary() |>
#   rename(trend_estimate = year_centered.trend,
#          trend_ci_lower = lower.HPD,
#          trend_ci_upper = upper.HPD)
# 
# res_draws_trend |>
#   mutate_if(is.numeric, round_half_up, digits = 3)

# # new levels of a specific subfield and hypothetical new journal
# res_draws_prevalence <- fit_uses_self_reports |>
#   emtrends(specs = ~ year_centered,
#            var = "year_centered",
#            at = list(year_centered = 0,
#                      subfield = "sf_4"), 
#            epred = TRUE, 
#            re_formula = NULL, 
#            allow_new_levels = TRUE, 
#            sample_new_levels = "uncertainty") |>
#   summary() |>
#   rename(trend_estimate = year_centered.trend,
#          trend_ci_lower = lower.HPD,
#          trend_ci_upper = upper.HPD)
# 
# res_draws_trend |>
#   mutate_if(is.numeric, round_half_up, digits = 3)

# estimate trend for either an existing subfield and journal, or an existing subfield and hypothetical journal, or hypothetical subfield and journal
est_trend <- function(fit, subfield, journal, re_level){
  fit |>
    emtrends(specs = ~ year_centered,
             var = "year_centered",
             at = list(year_centered = 0,
                       subfield = subfield,
                       journal = journal), 
             epred = TRUE, 
             re_formula = NULL, 
             allow_new_levels = TRUE,
             sample_new_levels = "uncertainty") |>
    summary() |>
    mutate(re_level = re_level) |>
    select(re_level,
           trend_estimate = year_centered.trend,
           trend_ci_lower = lower.HPD,
           trend_ci_upper = upper.HPD)
}

# est_trend(fit = fit_uses_self_reports,
#           subfield = "sf_4",
#           journal = "j_19")


# existing subfields and journals 
res_trend_journals <- 
  bind_rows(
    expand_grid(subfield = "General",
                journal = data_simulated_centered |>
                  filter(subfield == "General") |>
                  distinct(journal) |>
                  pull(journal)) |>
      mutate(res = pmap(list(list(fit_uses_self_reports),
                             subfield,
                             journal,
                             "journals"),
                        est_trend)) |>
      unnest(cols = c(res)),
    expand_grid(subfield = "Cognitive",
                journal = data_simulated_centered |>
                  filter(subfield == "Cognitive") |>
                  distinct(journal) |>
                  pull(journal)) |>
      mutate(res = pmap(list(list(fit_uses_self_reports),
                             subfield,
                             journal,
                             "journals"),
                        est_trend)) |>
      unnest(cols = c(res)),
    expand_grid(subfield = "Clinical",
                journal = data_simulated_centered |>
                  filter(subfield == "Clinical") |>
                  distinct(journal) |>
                  pull(journal)) |>
      mutate(res = pmap(list(list(fit_uses_self_reports),
                             subfield,
                             journal,
                             "journals"),
                        est_trend)) |>
      unnest(cols = c(res)),
    expand_grid(subfield = "Developmental",
                journal = data_simulated_centered |>
                  filter(subfield == "Developmental") |>
                  distinct(journal) |>
                  pull(journal)) |>
      mutate(res = pmap(list(list(fit_uses_self_reports),
                             subfield,
                             journal,
                             "journals"),
                        est_trend)) |>
      unnest(cols = c(res)),
    expand_grid(subfield = "I/O",
                journal = data_simulated_centered |>
                  filter(subfield == "I/O") |>
                  distinct(journal) |>
                  pull(journal)) |>
      mutate(res = pmap(list(list(fit_uses_self_reports),
                             subfield,
                             journal,
                             "journals"),
                        est_trend)) |>
      unnest(cols = c(res)),
    expand_grid(subfield = "Social/Personality",
                journal = data_simulated_centered |>
                  filter(subfield == "Social/Personality") |>
                  distinct(journal) |>
                  pull(journal)) |>
      mutate(res = pmap(list(list(fit_uses_self_reports),
                             subfield,
                             journal,
                             "journals"),
                        est_trend)) |>
      unnest(cols = c(res))
  )

# res_trend_journals |>
#   mutate_if(is.numeric, round_half_up, digits = 3)


# a hypothetical journal in existing subfields 
res_trend_subfields <- 
  expand_grid(subfield = data_simulated |>
                distinct(subfield) |>
                pull(subfield)) |>
  mutate(res = pmap(list(list(fit_uses_self_reports),
                         subfield,
                         "generic journal",
                         "subfields"),
                    est_trend)) |>
  unnest(cols = c(res))


# res_trend_subfields |>
#   mutate_if(is.numeric, round_half_up, digits = 3)


# # a hypothetical subfield and journal
# # nb this is similar to the grand mean, but incorporates the RE variance differently
# res_trend_field_hypothetical <- 
#   est_trend(fit = fit_uses_self_reports,
#             subfield = "generic new subfield",
#             journal = "generic new journal",
#             re_level = "field (hypothetical subfield and journal)")

# res_trend_field_hypothetical |>
#   mutate_if(is.numeric, round_half_up, digits = 3)


res_trends <- 
  bind_rows(res_trend_field,
            #res_trend_field_hypothetical,
            res_trend_subfields,
            res_trend_journals) |>
  mutate(subfield = ifelse(is.na(subfield), "", subfield),
         journal = ifelse(is.na(journal), "", journal),
         label = case_when(re_level == "field" ~ "Psychology",
                           #re_level == "field (hypothetical subfield and journal)" ~ "Field (single journal)",
                           re_level == "subfields" & journal == "" ~ subfield,
                           journal != "" ~ journal)) |>
  mutate(label = fct_relevel(
    label,
    "Psychology", 
    #"Field (single journal)", 
    
    "General", 
    "General journal 2", 
    "General journal 3", 
    "General journal 4", 
    "General journal 5", 
    "General journal 1", 
    
    "Cognitive", 
    "Cognitive journal 2", 
    "Cognitive journal 3", 
    "Cognitive journal 4", 
    "Cognitive journal 5", 
    "Cognitive journal 1", 
    
    "Clinical", 
    "Clinical journal 3", 
    "Clinical journal 4", 
    "Clinical journal 5", 
    "Clinical journal 1", 
    "Clinical journal 2", 
    
    "Developmental", 
    "Developmental journal 4", 
    "Developmental journal 5", 
    "Developmental journal 1", 
    "Developmental journal 2", 
    "Developmental journal 3", 
    
    "I/O", 
    "I/O journal 5", 
    "I/O journal 1", 
    "I/O journal 2", 
    "I/O journal 3", 
    "I/O journal 4", 
    
    "Social/Personality", 
    "Social/Personality journal 1", 
    "Social/Personality journal 2", 
    "Social/Personality journal 3", 
    "Social/Personality journal 4", 
    "Social/Personality journal 5"                   
  ),
  label = fct_rev(label)) |>
  select(label, re_level, subfield, journal, 
         trend_estimate, trend_ci_lower, trend_ci_upper) |>
  mutate(detectable = case_when(trend_ci_lower > 0 ~ TRUE,
                                trend_ci_upper < 0 ~ TRUE,
                                TRUE ~ FALSE))

# res_prevalence |>
#   distinct(label) |>
#   pull(label) |>
#   dput()

res_trends |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)


p_trend <- 
  ggplot(res_trends, aes(trend_estimate, label, color = detectable)) +
  geom_vline(xintercept = 0) +
  geom_linerangeh(aes(xmin = trend_ci_lower, xmax = trend_ci_upper)) +
  geom_point() +
  #coord_cartesian(xlim = c(0, 1)) +
  theme_linedraw() +
  scale_color_viridis_d(begin = 0.3, end = 0.7) +
  ylab("") +
  xlab("Trend (change in proportion per year)")

p_trend

```

### Plots multiple years 

#### Field

```{r}

data_summary_field <- data_simulated |>
  pivot_longer(cols = c("uses_self_reports", 
                        "uses_direct_behavioral_measures",
                        "uses_behavioral_proxy",
                        "uses_neuro_bio",
                        "uses_self_reports_about_behaviors",
                        "uses_generative_and_ability_tasks"),
               names_to = "measure_type",
               values_to = "used") |>
  group_by(year, measure_type) |>
  summarize(proportion = mean(used),
            proportion_se = plotrix::std.error(used)) |>
  filter(measure_type == "uses_self_reports")
  # pivot_wider(names_from = measure_type,
  #             values_from = proportion)

est_prevalence_field <- function(fit, year_centered){
  fit |>
    emmeans(specs = ~ 1,
            at = list(year_centered = year_centered),
            epred = TRUE,
            re_formula = NA,
            allow_new_levels = FALSE) |>
    summary() |>
    mutate(re_level = "field",
           year_centered = year_centered) |>
    select(re_level,
           year_centered,
           prevalence_estimate = emmean,
           prevalence_ci_lower = lower.HPD,
           prevalence_ci_upper = upper.HPD)
}

helper_function_field <- function(fit, year_centered){
  est_prevalence_field(fit = fit, year_centered = year_centered)
}

res_prevalence_field_years <- 
  map_dfr(seq(from = -7, to = 7, by = 1),
          helper_function_field,
          fit = fit_uses_self_reports) |>
  left_join(data_simulated_centered |> distinct(year, year_centered),
            by = "year_centered") |>
  mutate(field = "Psychology")


p_years_field <- ggplot() +
  geom_ribbon(data = res_prevalence_field_years, aes(year, ymin = prevalence_ci_lower, ymax = prevalence_ci_upper), fill = "skyblue", alpha = 0.5) +
  geom_smooth(data = res_prevalence_field_years, aes(year, prevalence_estimate),
              method = "lm", color = "black", size = 0.75, se = FALSE) +
  #geom_linerange(data = data_summary_field, aes(year, ymin = proportion - proportion_se*1.96, ymax = proportion + proportion_se*1.96)) + # simple wald CIs, not they way they're modelled but helps convey the uncertainty
  geom_point(data = data_summary_field, aes(year, proportion), size = 1) +
  theme_linedraw() +
  scale_x_continuous(breaks = c(2010, 2012, 2014, 2016, 2018, 2020, 2022)) +
  coord_cartesian(ylim = c(0,1)) +
  ylab("Prevalence") +
  xlab("Year") +
  facet_wrap(~ field)

```

#### Subfields

```{r}

data_summary_subfields <- data_simulated |>
  pivot_longer(cols = c("uses_self_reports", 
                        "uses_direct_behavioral_measures",
                        "uses_behavioral_proxy",
                        "uses_neuro_bio",
                        "uses_self_reports_about_behaviors",
                        "uses_generative_and_ability_tasks"),
               names_to = "measure_type",
               values_to = "used") |>
  group_by(subfield, year, measure_type) |>
  summarize(proportion = mean(used)) |>
  pivot_wider(names_from = measure_type,
              values_from = proportion)

est_prevalence_subfield <- function(fit, subfield, journal, re_level, year_centered){
  fit |>
    emmeans(specs = ~ 1,
            at = list(year_centered = year_centered,
                      subfield = subfield,
                      journal = journal),
            epred = TRUE,
            re_formula = NULL,
            allow_new_levels = TRUE,
            sample_new_levels = "uncertainty",
            rg.limit = 40000)  |>
    summary() |>
    mutate(re_level = re_level,
           year_centered = year_centered) |>
    select(re_level,
           year_centered,
           prevalence_estimate = emmean,
           prevalence_ci_lower = lower.HPD,
           prevalence_ci_upper = upper.HPD)
}

helper_function_subfield <- function(fit, year_centered){
  expand_grid(subfield = data_simulated |> distinct(subfield) |> pull(subfield)) |>
    mutate(res = pmap(list(list(fit), subfield, "generic new journal", "subfields", year_centered), est_prevalence_subfield)) |>
    unnest(cols = c(res)) 
}


res_prevalence_subfields_years <- 
  map_dfr(seq(from = -7, to = 7, by = 1),
          helper_function_subfield,
          fit = fit_uses_self_reports) |>
  left_join(data_simulated_centered |> distinct(year, year_centered),
            by = "year_centered")


p_years_subfields <- ggplot(res_prevalence_subfields_years, aes(year, prevalence_estimate)) +
  #geom_linerange(aes(ymin = prevalence_ci_lower, ymax = prevalence_ci_upper)) +
  geom_ribbon(aes(ymin = prevalence_ci_lower, ymax = prevalence_ci_upper), fill = "skyblue", alpha = 0.5) +
  geom_smooth(method = "lm", color = "black", size = 0.75, se = FALSE) +
  #geom_point(size = 1) +
  geom_point(data = data_summary_subfields, aes(year, uses_self_reports), size = 1) +
  #coord_cartesian(xlim = c(0, 1)) +
  theme_linedraw() +
  #scale_x_continuous(breaks = c(2010, 2012, 2014, 2016, 2018, 2020, 2022)) +
  scale_x_continuous(breaks = c(2010, 2014, 2018, 2022)) +
  coord_cartesian(ylim = c(0,1)) +
  ylab("Prevalence") +
  xlab("Year") +
  facet_wrap(~ subfield, ncol = 2)

```

```{r fig.height=10, fig.width=7}

library(patchwork)

p_years_field + p_years_subfields + plot_layout(ncol = 1, heights = c(0.25, 0.75)) 

```


```{r fig.height=6, fig.width=5}

p_years_field + p_years_subfields + plot_layout(ncol = 1, heights = c(0.35, 0.65)) 

```

```{r fig.height=6, fig.width=5}

library(grid)

watermark <- textGrob(
  label = "Simulated data",
  gp = gpar(fontsize = 20, col = "red", alpha = 0.5),
  rot = 30
)

(p_years_field + annotation_custom(
    grob = watermark,
    xmin = -Inf, xmax = Inf,
    ymin = -Inf, ymax = Inf
  )) +
  (p_years_subfields + annotation_custom(
    grob = watermark,
    xmin = -Inf, xmax = Inf,
    ymin = -Inf, ymax = Inf
  )) + 
  plot_layout(ncol = 1, heights = c(0.35, 0.65)) 

```

# Session info

```{r}

sessionInfo()

```


