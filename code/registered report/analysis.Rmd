---
title: "Measurement trends in psychology"
subtitle: "Analysis"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- update prior in this file and the other to match prior justification
- prevalence-and-trend plot might need to choose between marginal and conditional means. perhaps component plots too.
- try to reproduce "\n" warning/error in prevalence-and-trend plots and fix
- Add an (alternative) weighted model that weights by total articles published in each journal during that year? This should only produce results for the field as a whole, eg "Psychology (weighted by publications per journal per year)"
- remove/refactor plotting of summary data in plots, as the real data will be planned-missing

```{r setup, include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

```

```{r}

library(dplyr)
library(tidyr)
library(tibble)
library(stringr)
library(forcats)
library(readxl)
library(purrr)
library(readr)
library(janitor)
library(ggplot2)
library(scales)
library(ggstance)
library(ggcorrplot)
library(brms)
library(tidybayes)
library(emmeans)
library(marginaleffects)
library(knitr)
library(kableExtra)


dir.create("models")
dir.create("plots")

# function to save ggplots to disk
quicksave <- function(name, width, height){
  ggsave(paste0("plots/", name, ".pdf"), 
         device = "pdf",
         width = width, 
         height = height)
  
  ggsave(paste0("plots/", name, ".png"), 
         device = "png",
         dpi = 600,
         width = width, 
         height = height)
}

# round using half-up strategy and retaining trailing zeros
rnd <- function(x, digits = 2) {
  rounded_number <- round_half_up(x, digits)
  formatted_number <- sprintf(paste0("%.", digits, "f"), rounded_number)
  return(formatted_number)
}

```

# Data

## Simulate data

We will have two raters and they can either (a) score each article so that each one is scored twice, or (b) they could overlap eg 10% of articles for double scoring, so that more articles can be scored in total. Any input on this?

Each rater will score each measurement type as either present (1) or absent (0) in that article. There are 6 measurement types according to our scoring, and we see these categories as exhaustive. There will probably be 6 subfields and 5 journals per subfield. 

In the case of disagreements, should we solve this in data processing (get agreement between the authors/round down/round up) or model it? 

The total number of articles to be scored is still to be determined, as we don't know the average extraction time or the total resources available to us here (1 or 2 RAs or masters students or a mix).

When a journal has not existed for all years in the range, should we still extract the same number of articles from the years that do exist, or should we extract a proportionate number of articles (so the articles per year is stable)?

```{r}

set.seed(42)

n_articles_per_journal <- 15 # current estimate
n_journals_per_subfield <- 5
n_subfields <- 6

n_articles_total <- n_articles_per_journal * n_journals_per_subfield * n_subfields

data_simulated <-
  tibble(
    article_id = seq(from = 1, 
                     to = n_articles_total, 
                     by = 1),
    year = sample(x = 2009:2023,  # year range 
                  size = n_articles_total, 
                  replace = TRUE),
    directbehavioral = rbinom(n = n_articles_total,
                              size = 1, # values between 0 and 1
                              prob = .05), # probability of a given study containing such a measure
    behavioralproxy = rbinom(n = n_articles_total,
                             size = 1, # values between 0 and 1
                             prob = .1), # probability of a given study containing such a measure
    selfreportsaboutbehavior = rbinom(n = n_articles_total,
                                      size = 1, # values between 0 and 1
                                      prob = .1), # probability of a given study containing such a measure
    selfreportaboutsubjectivestate = c(rbinom(n = n_articles_total/2,
                          size = 1, # values between 0 and 1
                          prob = .95), # probability of a given study containing such a measure
                   rbinom(n = n_articles_total/2,
                          size = 1, # values between 0 and 1
                          prob = .70)),
    neurobiopsychophys = rbinom(n = n_articles_total,
                       size = 1, # values between 0 and 1
                       prob = .1), # probability of a given study containing such a measure
    cognitiveability = rbinom(n = n_articles_total,
                              size = 1, # values between 0 and 1
                              prob = .1) # probability of a given study containing such a measure
  ) |>
  mutate(article_id = as.factor(paste0("doi_", article_id)),
         subfield = c(rep("General", n_articles_per_journal * n_journals_per_subfield),
                      rep("Cognitive", n_articles_per_journal * n_journals_per_subfield),
                      rep("Clinical", n_articles_per_journal * n_journals_per_subfield),
                      rep("Developmental", n_articles_per_journal * n_journals_per_subfield),
                      rep("Industrial & Organizational", n_articles_per_journal * n_journals_per_subfield),
                      rep("Social & Personality", n_articles_per_journal * n_journals_per_subfield)),
         subfield = as.factor(subfield),
         journal_label = paste(subfield, "journal", seq(from = 1, to = 5)))

# weights
data_weights <- data_simulated |>
  distinct(subfield, journal_label) |>
  mutate(total_articles = round(runif(n = n(), min = 10*4, max = 10*12), 0),
         total_articles = case_when(subfield == "General" ~ total_articles + 80,
                                    subfield == "Clinical" ~ total_articles + 40,
                                    TRUE ~ total_articles),
         percent_of_all_articles = total_articles/sum(total_articles)*100)

data_simulated <- data_simulated |>
  left_join(data_weights, by = c("subfield", "journal_label"))

journal_names <- read_xlsx("../../data/registered report/journals.xlsx")

data_simulated <- data_simulated |>
  left_join(journal_names, by = c("subfield", "journal_label")) |>
  rename(journal = journal_abbreviation)

# save for reproducibility
if(!file.exists("../../data/registered report/simulated/data_simulated.csv")){
  write_csv(data_simulated, "../../data/registered report/simulated/data_simulated.csv")
}

# pull the journal abbreviations, for ordering figures and tables later
subfield_and_journal_labels <- journal_names |>
  pull(journal_abbreviation)

subfield_and_journal_labels_without_subfields <- journal_names |>
  drop_na(journal_name) |>
  pull(journal_abbreviation)

```

### Check

```{r}

data_simulated |>
  count(subfield, journal) |>
  kable() |>
  kable_classic(full_width = FALSE)

data_simulated |>
  summarize(mean_directbehavioral = mean(directbehavioral),
            mean_behavioralproxy = mean(behavioralproxy),
            mean_selfreportsaboutbehavior = mean(selfreportsaboutbehavior),
            mean_selfreportaboutsubjectivestate = mean(selfreportaboutsubjectivestate),
            mean_neurobiopsychophys = mean(neurobiopsychophys),
            mean_cognitiveability = mean(cognitiveability)) |>
  mutate_all(round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

data_simulated |>
  group_by(subfield, journal) |>
  summarize(mean_directbehavioral = mean(directbehavioral),
            mean_behavioralproxy = mean(behavioralproxy),
            mean_selfreportsaboutbehavior = mean(selfreportsaboutbehavior),
            mean_selfreportaboutsubjectivestate = mean(selfreportaboutsubjectivestate),
            mean_neurobiopsychophys = mean(neurobiopsychophys),
            mean_cognitiveability = mean(cognitiveability)) |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Real data

```{r}

# simulated data will be replaced with real data after collection
# data_processed <- read_csv("../../data/processed/data_processed.csv")

```

# Analyze

## Justification of priors

### Intuitions for log-odds

We employ a logistic regression (Bernoulli link function), so priors for the intercepts, b_year_centered, and sd of the random effects are on the log-odds scale.

To illustrate and develop an intuition for log-odds values, we can convert probabilities to log-odds and table/plot them against one another.

```{r}

df_probability_logodds <- 
  tibble(probability = seq(0, 1, by = 0.001)) |>
  mutate(logodds = qlogis(probability))

df_probability_logodds |>
  filter(probability %in% c(0.01, 0.5, 0.99)) |>
  kable() |>
  kable_classic(full_width = FALSE)

ggplot(df_probability_logodds, aes(probability, logodds)) +
  geom_point(size = 0.1) +
  geom_vline(xintercept = 0.01, linetype = "dashed", color = "#359EAAFF") +
  geom_vline(xintercept = 0.99, linetype = "dashed", color = "#359EAAFF") +
  theme_linedraw() +
  scale_x_continuous(breaks = breaks_pretty(n = 10)) +
  xlab("Probability") +
  ylab("Log-odds")

```

This shows that a probability of 50% = log-odds of 0. More importantly, |log-odds| > 4.6 refer to probabilities of less than 1%. So, to say that there is a log-odds Â±5, 6, or 7 of something occurring means that it almost never/always occurs. For our study, prevalences in the 1-99% range are reasonable. 

### Intercepts (prevalences)

We are looking to employ weakly regularizing priors, i.e., those that help the model converge, and therefore exclude impossible/highly implausible values, without imposing strong prior beliefs onto the model. Given this goal, our priors should therefore both cover the probability of 1-99% range (and a bit beyond) and exclude probabilities that approach Â±Inf, therefore |log-odds| of Â±4.6 or so. A normally distributed prior on the log-odds scale is therefore useful here.

We will choose specific locations based our a priori beliefs about the prevalence of different types of measures. However, given the width of the prior on each, this won't make much difference. It's more about indicating to the model what is unlikely (e.g., only 1% of studies using self-report measures) rather than a strong belief about what is likely.

Specifically, we choose three different priors depending on our beliefs about each type of measure:

- No strong beliefs about prevalence: mean = .50 (on probability scale), sd = 1.4 (on log-odds scale). This prior serves only to specify that very high or low prevalences are less likely.
- Prior belief prevalence is high: mean = .70 (on probability scale), sd = 1 (on log-odds scale). This prior serves to specify that low prevalences less likely.
- Prior belief prevalence is low: mean = .25 (on probability scale), sd = 1 (on log-odds scale). This prior serves to specify that high prevalences less likely. 

The asymmetry between low and high is intentional, reflecting our stronger belief that low prevalences are lower than high prevalence are high.

```{r}

illustrate_intercept_prior <- function(mean_prob, sd_logodds){
  df_normal_logodds <- 
    tibble(logodds = rnorm(mean = qlogis(mean_prob), sd = sd_logodds, n = 10000000)) |>
    mutate(probability = plogis(logodds))
  
  ggplot(df_normal_logodds, aes(probability)) +
    geom_density(fill = "grey20") +
    theme_linedraw() +
    scale_x_continuous(breaks = breaks_pretty(n = 10)) +
    xlab("Probability") +
    ylab("Density") +
    ggtitle(paste0("Prevalence prior: \nnormal(M = qlogis(", mean_prob, "), SD = 1) log-odds distribution converted to probabilities"))
}

illustrate_intercept_prior(mean_prob = .70, sd_logodds = 1) # self reports of subjective experience
illustrate_intercept_prior(mean_prob = .25, sd_logodds = 1) # direct behavioral measures
illustrate_intercept_prior(mean_prob = .50, sd_logodds = 1.4) # all other modes, given our very weak beliefs and the potential for variation between subfields/journals 

qlogis(.50)
qlogis(.70)
qlogis(.25)

```

### Slopes (trends)

Normal distributions (on the log-odds scale) are also useful for the slopes. However, because the slopes compound over years, relatively small values of slope can produce large changes in the prevalence over the 15 year period. 

The below visualizes different (a) values of prevalence (probability scale) in the middle year (the mean of the prior distribution) and (b) values of 2 X SD of the prior distribution (on the log-odds scale), which corresponds to roughly 95% of the range of values covered by the prior. 

```{r}

illustrate_trend_prior <- function(mean_prevalence_prob, sd_trend_prob){
  df_probability_logodds <- 
    tibble(year_centered = seq(-7, +7, by = 1)) |>
    expand_grid(b1 = seq(sd_trend_prob*-2, sd_trend_prob*2, by = .01)) |>
    mutate(logodds = qlogis(mean_prevalence_prob) + (b1 * year_centered),
           probability = plogis(logodds),
           year = year_centered + 2016)
  
  ggplot(df_probability_logodds, aes(year, probability, color = b1, group = b1)) +
    geom_line() +
    scale_x_continuous(breaks = breaks_pretty(n = 10)) +
    theme_linedraw() +
    ylim(0, 1) +
    ylab("Prevalence") +
    xlab("Year") +
    ggtitle(paste0("Prevalence prior: \nnormal(M = qlogis(", mean_prevalence_prob, "), SD = ", sd_trend_prob, ") log-odds distribution converted to probabilities"))
}

illustrate_trend_prior(mean_prevalence_prob = .10, sd_trend_prob = .1)
illustrate_trend_prior(mean_prevalence_prob = .50, sd_trend_prob = .1)
illustrate_trend_prior(mean_prevalence_prob = .90, sd_trend_prob = .1)

illustrate_trend_prior(mean_prevalence_prob = .10, sd_trend_prob = .2)
illustrate_trend_prior(mean_prevalence_prob = .50, sd_trend_prob = .2) # probably for the best
illustrate_trend_prior(mean_prevalence_prob = .90, sd_trend_prob = .2)

illustrate_trend_prior(mean_prevalence_prob = .10, sd_trend_prob = .3)
illustrate_trend_prior(mean_prevalence_prob = .50, sd_trend_prob = .3)
illustrate_trend_prior(mean_prevalence_prob = .90, sd_trend_prob = .3)

```

A normal prior for the slopes with M = 0 and SD = .20 allows, regardless of the prevalence in the middle year, for very large trends across years. E.g., for prevalence = .50 in the middle year, the 95% of the prior allows for changes of from roughly 5% in the first year to 95% in the final year. This is unlikely, but the point of the these weakly regularising priors is to aid convergence by excluding truly impossible or highly implausible values. This prior does this. 

### SD of the random effects

The width of the SDs on the random effects (subfield and subfield:journal) also require a prior, still on the log-odds scale, which refers to the degree of variability between subfields/journals.

McElreath uses exponential(1) as a weakly regularizing prior for SDs on random effects frequently in the 2nd edition of Statistical Rethinking, and therefore we do here. Again, this serves to exclude truly impossible or highly implausible values (e.g., 10 or 100) to aid convergence, rather than to assert strong prior beliefs. The below plots such an exp(1) distribution.

```{r}

prior_sd <- tibble(sd = seq(0, 4, by = 0.1)) |>
  mutate(density = dexp(sd, rate = 1))  

ggplot(prior_sd, aes(sd, density)) +
  geom_area() +
  xlab("SD of the random effects (on the log-odds scale)") +
  ylab("Density") +
  theme_linedraw()

```

### Correlations among the random effects

{brms} uses a Lewandowski-Kurowicka-Joe (LKJ) prior with eta = 1, i.e., a flat distribution. LKJ depends on the number of correlations involved, and we have a relatively large amount (21), so values of eta above 1, which would regularize correlations towards zero, would be more aggressive than the weakly regularising prior that we're looking for. LKJ(1) is merely skeptical of large correlations, but is applied to the matrix as a whole, so a minority of large correlations are still possible with this prior. We therefore retain the {brms} default prior of lkj(1).

## Fit model

```{r}

# # real data
# data_centered <- data_processed |>
#   mutate(year_centered = year - 2016)

# simulated data for development
data_centered <- data_simulated |>
  mutate(year_centered = year - 2016)

# specify Wilkinson notation for the model
# note that the | p | and | q | syntax specifies that the correlations among the random effects be modelled (ie not assumed to be zero)
formulas <- 
  bf(formula = directbehavioral | weights(percent_of_all_articles) ~               1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
  bf(formula = behavioralproxy | weights(percent_of_all_articles) ~                1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
  bf(formula = selfreportsaboutbehavior | weights(percent_of_all_articles) ~       1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
  bf(formula = selfreportaboutsubjectivestate | weights(percent_of_all_articles) ~ 1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
  bf(formula = neurobiopsychophys | weights(percent_of_all_articles) ~             1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
  bf(formula = cognitiveability | weights(percent_of_all_articles) ~               1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal))

# # it is plausible that a reviewer asks us for unweighted models for robustness, although it is harder to know how to interpret the field-wide prevalences and trends given meaningful differences in size of the subfields. nonetheless, I retain the code here.
# formulas <- 
#   bf(formula = directbehavioral ~               1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
#   bf(formula = behavioralproxy ~                1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
#   bf(formula = selfreportsaboutbehavior ~       1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
#   bf(formula = selfreportaboutsubjectivestate ~ 1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
#   bf(formula = neurobiopsychophys ~             1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) +
#   bf(formula = cognitiveability ~               1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal)) 

# specify priors
priors <- 
  prior(normal(-1.10, 1.0), class = Intercept, resp = "directbehavioral") + # qlogis(.25)
  prior(normal(+0.00, 1.4), class = Intercept, resp = "behavioralproxy") + # qlogis(.50)
  prior(normal(+0.00, 1.4), class = Intercept, resp = "selfreportsaboutbehavior") + # qlogis(.50)
  prior(normal(+0.85, 1.0), class = Intercept, resp = "selfreportaboutsubjectivestate") + # qlogis(.70)
  prior(normal(+0.00, 1.4), class = Intercept, resp = "neurobiopsychophys") + # qlogis(.50)
  prior(normal(+0.00, 1.4), class = Intercept, resp = "cognitiveability") + # qlogis(.50)
  
  prior(normal(0, 0.2),   class = b,         resp = "directbehavioral") +
  prior(normal(0, 0.2),   class = b,         resp = "behavioralproxy") + 
  prior(normal(0, 0.2),   class = b,         resp = "selfreportsaboutbehavior") + 
  prior(normal(0, 0.2),   class = b,         resp = "selfreportaboutsubjectivestate") + 
  prior(normal(0, 0.2),   class = b,         resp = "neurobiopsychophys") + 
  prior(normal(0, 0.2),   class = b,         resp = "cognitiveability") + 
  
  prior(exponential(1),   class = sd,        resp = "directbehavioral") +
  prior(exponential(1),   class = sd,        resp = "behavioralproxy") + 
  prior(exponential(1),   class = sd,        resp = "selfreportsaboutbehavior") + 
  prior(exponential(1),   class = sd,        resp = "selfreportaboutsubjectivestate") + 
  prior(exponential(1),   class = sd,        resp = "neurobiopsychophys") + 
  prior(exponential(1),   class = sd,        resp = "cognitiveability") + 
  
  prior(lkj_corr_cholesky(1), class = cor)

# fit model
fitted_model <- brm(
  formula = formulas,
  family  = bernoulli(link = "logit"),
  prior   = priors,
  data    = data_centered,
  cores   = parallel::detectCores(),
  seed    = 42,
  iter    = 8000, 
  warmup  = 4000, 
  
  # sample prior only for testing and dev
  #sample_prior = "only",
  #file = "models/fitted_model_prioronly"
  
  # fit using simulated data for testing and dev
  sample_prior = "no",
  file = "models/fitted_model_simulated_data"
  
  # when real data is in after Stage 1 acceptance, fit using real data
  #sample_prior = "no",
  #file = "models/fitted_model"
  
  # if there are divergent transitions, can be increased from the default to eg .99 
  #control = list(adapt_delta = .99)
)

```

## Model diagnostics

```{r eval=FALSE, include=FALSE}

summary(fitted_model)

pp_check(fitted_model, ndraws = 100, resp = "directbehavioral")
pp_check(fitted_model, ndraws = 100, resp = "behavioralproxy")
pp_check(fitted_model, ndraws = 100, resp = "selfreportsaboutbehavior")
pp_check(fitted_model, ndraws = 100, resp = "selfreportaboutsubjectivestate")
pp_check(fitted_model, ndraws = 100, resp = "neurobiopsychophys")
pp_check(fitted_model, ndraws = 100, resp = "cognitiveability")

plot(fitted_model, comparisons = TRUE, ask = FALSE)

```

## Extract estimates

### Resources 

For consistent and precise terminology, we relied on [Heiss (2021)](https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/#overall-summary-of-different-approaches) and [Heiss (2022)](https://www.andrewheiss.com/blog/2022/05/20/marginalia/#tldr-overall-summary-of-all-these-marginal-effects-approaches) which describe marginal vs conditional effects implemented in the marginaleffects vs emmeans packages.

Following Heiss's (2021, 2022) terminology, we extract:

- Marginal Global Mean (aka the Average Marginal Effect, AME): "typically, psychology articles..." - intervals are akin to confidence intervals in Frequentist meta analysis
- Conditional Global Mean (aka the Group Average Marginal Effect, G-AME)): "a typical psychology article..." - intervals are akin to prediction intervals in Frequentist meta analysis, will be equal or wider than the AME estimates.
- Conditional Mean by Subfield
- Conditional Mean by Journal

### Prevalence

```{r}

if(exists("models/posterior_prevalence.rds")){
  posterior_prevalence <- read_rds("models/posterior_prevalence.rds")
} else {
  
  est_prevalence <- function(subfield = "hypothetical typical subfield", journal = "hypothetical typical journal", type = c("conditional", "marginal"), year_centered = 0, fit) {
    
    # reminder of the distinction: 
    # "a typical journal..." (conditional effect, taking levels of the random effects into account, whether existing or new hypothetical ones) vs.
    # "typically, journals..." (marginal effect, ignoring the random effects, therefore likely producing wider estimates given any heterogeneity among the random effects)
    
    if(type == "conditional") {
      # conditional effect for either existing levels of the random effects if specified,
      # or if not specified then for hypothetical new representative levels 
      if(subfield == "hypothetical typical subfield"){
        subfield_dummy = factor("hypothetical typical subfield", levels = unique(fit$data$subfield))
      } else {
        subfield_dummy <- subfield
      }
      
      if(journal == "hypothetical typical journal"){
        journal_dummy = factor("hypothetical typical journal", levels = unique(fit$data$journal))
      } else {
        journal_dummy <- journal
      }
      
      res <- 
        predictions(model = fitted_model,
                    newdata = datagrid(year_centered = year_centered,
                                       subfield = subfield_dummy,
                                       journal = journal_dummy),
                    re_formula = NULL,
                    allow_new_levels = TRUE) |>
        select(outcome = group, 
               prevalence_estimate = estimate,
               prevalence_ci_lower = conf.low,
               prevalence_ci_upper = conf.high)
      
    } else if (type == "marginal") {
      res <- 
        predictions(model = fit,
                    newdata = datagrid(year_centered = year_centered),
                    re_formula = NA,  
                    allow_new_levels = FALSE) |>
        select(outcome = group, 
               prevalence_estimate = estimate,
               prevalence_ci_lower = conf.low,
               prevalence_ci_upper = conf.high)
    }
    
    return(res)
  }
  
  # field - marginal effect
  posterior_prevalence_field_marginal <- 
    expand_grid(subfield = "across field", 
                journal = "across field",
                type = "marginal",
                re_level = "field") |>
    tibble(res = pmap(list(subfield, journal, type), 
                      est_prevalence, 
                      fit = fitted_model)) |>
    unnest(res) 
  
  # field - conditional effect
  posterior_prevalence_field_conditional <- 
    expand_grid(subfield = "hypothetical typical subfield", 
                journal = "hypothetical typical journal",
                type = "conditional",
                re_level = "field") |>
    tibble(res = pmap(list(subfield, journal, type), 
                      est_prevalence, 
                      fit = fitted_model)) |>
    unnest(res) 
  
  # subfields
  posterior_prevalence_subfields <- 
    expand_grid(data_centered |>
                  distinct(subfield),
                journal = "hypothetical typical journal",
                type = "conditional",
                re_level = "subfields") |>
    tibble(res = pmap(list(subfield, journal, type), 
                      est_prevalence, 
                      fit = fitted_model)) |>
    unnest(res) 
  
  # journals
  posterior_prevalence_journals <- 
    expand_grid(data_centered |>
                  distinct(subfield, journal),
                type = "conditional",
                re_level = "journals") |>
    tibble(res = pmap(list(subfield, journal, type), 
                      est_prevalence, 
                      fit = fitted_model)) |>
    unnest(res) 
  
  # combine
  posterior_prevalence <- 
    bind_rows(posterior_prevalence_field_marginal,
              posterior_prevalence_field_conditional,
              posterior_prevalence_subfields,
              posterior_prevalence_journals) |>
    mutate(label = case_when(re_level == "field" & type == "marginal" ~ "Psychology (marginal)",
                             re_level == "field" & type == "conditional" ~ "Psychology (conditional)",
                             re_level == "subfields" & journal == "hypothetical typical journal" ~ subfield,
                             journal != "hypothetical typical journal" & !is.na(journal) ~ journal)) |>
    mutate(label = fct_relevel(label,
                               "Psychology (marginal)",
                               "Psychology (conditional)",
                               subfield_and_journal_labels),
    label = fct_rev(label)) |>
    mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                               outcome == "behavioralproxy" ~ "Behavioral Proxy",
                               outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                               outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about Subjective States",
                               outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                               outcome == "cognitiveability" ~ "Cognitive Ability",
                               TRUE ~ outcome),
           outcome = fct_relevel(outcome, 
                                 "Direct Behavioral",		
                                 "Behavioral Proxy",
                                 "Self-Report about Behavior",
                                 "Self-Report about Subjective States",
                                 "Neuro/Bio/Psychophys",
                                 "Cognitive Ability"),
           outcome = fct_rev(outcome),
           subfield = fct_relevel(subfield,
                                  "hypothetical typical subfield",
                                  "General",
                                  "Clinical",
                                  "Cognitive",
                                  "Developmental",
                                  "Industrial & Organizational",
                                  "Social & Personality")) |>
    mutate(prevalence_category = case_when(prevalence_estimate < .05 ~ "Rare",
                                           prevalence_estimate >= .05 & prevalence_estimate < .10 ~ "Uncommon",
                                           prevalence_estimate >= .10 & prevalence_estimate < .25 ~ "Occasional",
                                           prevalence_estimate >= .25 & prevalence_estimate < .50 ~ "Common",
                                           prevalence_estimate >= .50 ~ "Frequent"),
           prevalence_results = paste0(rnd(prevalence_estimate), ", 95% CI [", rnd(prevalence_ci_lower), ", ", rnd(prevalence_ci_upper), "]")) |>
    select(outcome, label, re_level, type, subfield, journal, 
           prevalence_estimate, prevalence_ci_lower, prevalence_ci_upper, prevalence_category, prevalence_results) |>
    arrange(outcome, desc(label), subfield)
  
  write_rds(posterior_prevalence, "models/posterior_prevalence.rds")
}

# print table
posterior_prevalence |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

#### Plot field + subfields

```{r fig.height=6, fig.width=11}

p_prevalence_subfields <- posterior_prevalence |>
  filter(re_level != "journals") |>
  ggplot(aes(prevalence_estimate, outcome)) +
  geom_rect(aes(xmin = 0.00, xmax = 0.05, ymin = -Inf, ymax = Inf, color = NULL),
            fill = "grey65") +
  geom_rect(aes(xmin = 0.05, xmax = 0.10, ymin = -Inf, ymax = Inf, color = NULL),
            fill = "grey73") +
  geom_rect(aes(xmin = 0.10, xmax = 0.25, ymin = -Inf, ymax = Inf, color = NULL),
            fill = "grey80") +
  geom_rect(aes(xmin = 0.25, xmax = 0.50, ymin = -Inf, ymax = Inf, color = NULL),
            fill = "grey90") +
  geom_rect(aes(xmin = 0.50, xmax = 1.00, ymin = -Inf, ymax = Inf, color = NULL),
            fill = "grey95") +
  annotate("text", x = 0.0250, y = "Self-Report about Behavior", label = "Rare",       size = 4, color = "grey30", angle = 90) +
  annotate("text", x = 0.0725, y = "Self-Report about Behavior", label = "Uncommon",   size = 4, color = "grey40", angle = 90) +
  annotate("text", x = 0.1750, y = "Self-Report about Behavior", label = "Occasional", size = 4, color = "grey50", angle = 90) +
  annotate("text", x = 0.3750, y = "Self-Report about Behavior", label = "Common",     size = 4, color = "grey60", angle = 90) +
  annotate("text", x = 0.7500, y = "Self-Report about Behavior", label = "Frequent",   size = 4, color = "grey65", angle = 90) +
  geom_linerangeh(aes(xmin = prevalence_ci_lower, xmax = prevalence_ci_upper), position = position_dodge(width = .7)) +
  geom_point(position = position_dodge(width = .7)) +
  coord_cartesian(xlim = c(0, 1)) +
  theme_linedraw() + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.spacing = unit(1, "lines")) +  # Increase spacing between facets  
  ylab("") +
  xlab("Prevalence") +
  #scale_x_continuous(labels = scales::label_percent(), breaks = c(0, 0.05, 0.1, 0.25, 0.5, 1)) +
  scale_x_continuous(labels = c("0%", "5%", "10%", "25%", "50%", "75%", "100%"),
                     breaks = c(0, 0.05, 0.10, 0.25, 0.50, 0.75, 1),
                     minor_breaks = NULL,
                     expand = c(0,0)) +
  guides(color = guide_legend(title = "Measure mode",
                              reverse = TRUE)) +
  facet_wrap(~ fct_rev(label), ncol = 2)

p_prevalence_subfields

quicksave("p_prevalence_subfields", 11, 6)

```

#### Plot journals

```{r fig.height=10, fig.width=12}

p_prevalence_journals <- posterior_prevalence |>
  filter(re_level == "journals") |>
  mutate(label = fct_relevel(label, subfield_and_journal_labels_without_subfields),
         label = fct_rev(label),
         outcome = fct_relevel(outcome, 
                               "Direct Behavioral",		
                               "Behavioral Proxy",
                               "Self-Report about Behavior",
                               "Self-Report about Subjective States",
                               "Neuro/Bio/Psychophys",
                               "Cognitive Ability")) |>
  ggplot(aes(prevalence_estimate, label, color = subfield)) +
  geom_linerangeh(aes(xmin = prevalence_ci_lower, xmax = prevalence_ci_upper)) +
  geom_point() +
  coord_cartesian(xlim = c(0, 1)) +
  theme_linedraw() +
  ylab("") +
  xlab("Prevalence") +
  guides(color = guide_legend(title = "Measure mode")) +
  facet_wrap(~ outcome, ncol = 3)

p_prevalence_journals

quicksave("p_prevalence_journals", 12, 10)

```

### Trend

```{r}

if(exists("models/posterior_trends.rds")){
  posterior_trends <- read_rds("models/posterior_trends.rds")
} else {
  
  est_trend <- function(subfield = "hypothetical typical subfield", journal = "hypothetical typical journal", type = c("conditional", "marginal"), fit) {
    
    # reminder of the distinction: 
    # "a typical journal..." (conditional effect, taking levels of the random effects into account, whether existing or new hypothetical ones) vs.
    # "typically, journals..." (marginal effect, ignoring the random effects, therefore likely producing wider estimates given any heterogeneity among the random effects)
    
    if(type == "conditional") {
      # conditional effect for either existing levels of the random effects if specified,
      # or if not specified then for hypothetical new representative levels 
      if(subfield == "hypothetical typical subfield"){
        subfield = factor("hypothetical typical subfield", levels = unique(fit$data$subfield))
      }
      
      if(journal == "hypothetical typical journal"){
        journal = factor("hypothetical typical journal", levels = unique(fit$data$journal))
      }
      
      res <- 
        slopes(model = fit,
               variables = "year_centered", 
               newdata = datagrid(subfield = subfield,
                                  journal = journal),
               re_formula = NULL, 
               allow_new_levels = TRUE) |>
        select(outcome = group,
               trend_estimate = estimate,
               trend_ci_lower = conf.low,
               trend_ci_upper = conf.high)
      
    } else if (type == "marginal") {
      res <- 
        avg_slopes(model = fit,
                   variables = "year_centered",
                   re_formula = NA, 
                   allow_new_levels = FALSE) |>
        select(outcome = group,
               trend_estimate = estimate,
               trend_ci_lower = conf.low,
               trend_ci_upper = conf.high)
    }
    
    return(res)
  }
  
  # field - marginal effect
  posterior_trend_field_marginal <- 
    expand_grid(subfield = "across field", 
                journal = "across field",
                type = "marginal",
                re_level = "field") |>
    tibble(res = pmap(list(subfield, journal, type), 
                      est_trend, 
                      fit = fitted_model)) |>
    unnest(res) 
  
  # field - conditional effect
  posterior_trend_field_conditional <- 
    expand_grid(subfield = "hypothetical typical subfield", 
                journal = "hypothetical typical journal",
                type = "conditional",
                re_level = "field") |>
    tibble(res = pmap(list(subfield, journal, type), 
                      est_trend, 
                      fit = fitted_model)) |>
    unnest(res) 
  
  # subfields
  posterior_trend_subfields <- 
    expand_grid(data_centered |>
                  distinct(subfield),
                journal = "hypothetical typical journal",
                type = "conditional",
                re_level = "subfields") |>
    tibble(res = pmap(list(subfield, journal, type), 
                      est_trend, 
                      fit = fitted_model)) |>
    unnest(res) 
  
  # journals
  posterior_trend_journals <- 
    expand_grid(data_centered |>
                  distinct(subfield, journal),
                type = "conditional",
                re_level = "journals") |>
    tibble(res = pmap(list(subfield, journal, type), 
                      est_trend, 
                      fit = fitted_model)) |>
    unnest(res) 
  
  # combine
  posterior_trends <- 
    bind_rows(posterior_trend_field_marginal,
              posterior_trend_field_conditional,
              posterior_trend_subfields,
              posterior_trend_journals) |>
    mutate(subfield = ifelse(is.na(subfield), "", subfield),
           journal = ifelse(is.na(journal), "", journal)) |>
    mutate(label = case_when(re_level == "field" & type == "marginal" ~ "Psychology (marginal)",
                             re_level == "field" & type == "conditional" ~ "Psychology (conditional)",
                             re_level == "subfields" & journal == "hypothetical typical journal" ~ subfield,
                             journal != "hypothetical typical journal" & !is.na(journal) ~ journal)) |>
    mutate(label = fct_relevel(label,
                               "Psychology (marginal)",
                               "Psychology (conditional)",
                               subfield_and_journal_labels),
    label = fct_rev(label)) |>
    mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                               outcome == "behavioralproxy" ~ "Behavioral Proxy",
                               outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                               outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about Subjective States",
                               outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                               outcome == "cognitiveability" ~ "Cognitive Ability",
                               TRUE ~ outcome),
           outcome = fct_relevel(outcome, 
                                 "Direct Behavioral",		
                                 "Behavioral Proxy",
                                 "Self-Report about Behavior",
                                 "Self-Report about Subjective States",
                                 "Neuro/Bio/Psychophys",
                                 "Cognitive Ability"),
           outcome = fct_rev(outcome),
           subfield = fct_relevel(subfield,
                                  "hypothetical typical subfield",
                                  "General",
                                  "Clinical",
                                  "Cognitive",
                                  "Developmental",
                                  "Industrial & Organizational",
                                  "Social & Personality")) |>
    mutate(trend_category = case_when(trend_ci_lower > 0 ~ "Increasing",
                                      trend_ci_upper < 0 ~ "Decreasing",
                                      TRUE ~ "No trend detected"),
           trend_results = paste0(rnd(trend_estimate), ", 95% CI [", rnd(trend_ci_lower), ", ", rnd(trend_ci_upper), "]")) |>
    select(outcome, label, re_level, type, subfield, journal, 
           trend_estimate, trend_ci_lower, trend_ci_upper, trend_category, trend_results) |>
    arrange(outcome, desc(label), subfield)
  
  write_rds(posterior_trends, "models/posterior_trends.rds")
}

# print table
posterior_trends |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

#### Plot field + subfields

```{r fig.height=6, fig.width=11}

# show_col(viridis::mako(25))
# viridis::mako(25)

p_trend_subfields <- posterior_trends |>
  filter(re_level != "journals") |>
  mutate(label = fct_relevel(label,
                             "Psychology (marginal)",
                             "Psychology (conditional)",
                             "General",
                             "Clinical",
                             "Cognitive",
                             "Developmental",
                             "Industrial & Organizational",
                             "Social & Personality")) |>
  ggplot(aes(trend_estimate, outcome, color = trend_category)) +
  geom_vline(xintercept = 0, linetype = "dotted") +
  geom_vline(xintercept = 0, linetype = "dotted") +
  geom_linerangeh(aes(xmin = trend_ci_lower, xmax = trend_ci_upper)) +
  geom_point() +
  #coord_cartesian(xlim = c(-.1, .1)) +
  theme_linedraw() +
  ylab("") +
  xlab("Trend (change per year)") +
  scale_x_continuous(labels = scales::label_percent(), breaks = breaks_pretty()) +
  scale_color_manual(values = c("#38629DFF", "#2B1C35FF", "#359EAAFF")) +
  guides(color = guide_legend(title = "Trend",
                              reverse = TRUE)) +
  facet_wrap(~ label, ncol = 2)

p_trend_subfields

quicksave("p_trend_subfields", 11, 6)

```

#### Plot journals

```{r fig.height=10, fig.width=12}

p_trend_journals <- posterior_trends |>
  filter(re_level == "journals") |>
  mutate(label = fct_relevel(label, subfield_and_journal_labels_without_subfields),
         label = fct_rev(label)) |>
  ggplot(aes(trend_estimate, label, color = subfield)) + # color = trend_category, 
  geom_vline(xintercept = 0, linetype = "dotted") +
  geom_linerangeh(aes(xmin = trend_ci_lower, xmax = trend_ci_upper), position = position_dodge(width = .8)) +
  geom_point(position = position_dodge(width = .8)) +
  #coord_cartesian(xlim = c(-.1, .1)) +
  theme_linedraw() +
  ylab("") +
  xlab("Trend (change per year)") +
  scale_x_continuous(labels = scales::label_percent(), breaks = breaks_pretty()) +
  #scale_color_manual(values = c("#38629DFF", "#2B1C35FF", "#359EAAFF")) +
  guides(color = guide_legend(title = "Trend")) +
  facet_wrap(~ outcome, ncol = 3)

p_trend_journals

quicksave("p_trend_journals", 12, 10)

```

## Plot prevalences and trends

### Field

```{r fig.height=8, fig.width=9}

# calculate empirical means
data_summary_field <- data_centered |>
  pivot_longer(cols = c("directbehavioral", 
                        "behavioralproxy",
                        "selfreportsaboutbehavior",
                        "selfreportaboutsubjectivestate",
                        "neurobiopsychophys",
                        "cognitiveability"),
               names_to = "outcome",
               values_to = "used") |>
  group_by(year, outcome) |>
  summarize(proportion = mean(used)) |>
  mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                             outcome == "behavioralproxy" ~ "Behavioral Proxy",
                             outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                             outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about Subjective States",
                             outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                             outcome == "cognitiveability" ~ "Cognitive Ability"),
         outcome = fct_relevel(outcome, 
                               "Direct Behavioral",		
                               "Behavioral Proxy",
                               "Self-Report about Behavior",
                               "Self-Report about Subjective States",
                               "Neuro/Bio/Psychophys",
                               "Cognitive Ability"))

if(exists("models/posterior_prevalence_field_marginal_by_year.rds") &
   exists("models/posterior_prevalence_field_conditional_by_year.rds")){
  
  posterior_prevalence_field_marginal_by_year <- 
    read_rds("models/posterior_prevalence_field_marginal_by_year.rds")
  
  posterior_prevalence_field_conditional_by_year <- 
    read_rds("models/posterior_prevalence_field_conditional_by_year.rds")
  
} else {
  
  # field - marginal effect
  posterior_prevalence_field_marginal_by_year <- 
    expand_grid(data_centered |>
                  distinct(year, year_centered),
                subfield = "across field", 
                journal = "across field",
                type = "marginal",
                re_level = "field") |>
    tibble(res = pmap(list(subfield, journal, type, year_centered), 
                      est_prevalence, 
                      fit = fitted_model)) |>
    unnest(res) |>
    mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                               outcome == "behavioralproxy" ~ "Behavioral Proxy",
                               outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                               outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about Subjective States",
                               outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                               outcome == "cognitiveability" ~ "Cognitive Ability"),
           outcome = fct_relevel(outcome, 
                                 "Direct Behavioral",		
                                 "Behavioral Proxy",
                                 "Self-Report about Behavior",
                                 "Self-Report about Subjective States",
                                 "Neuro/Bio/Psychophys",
                                 "Cognitive Ability"))
  
  # field - conditional effect
  posterior_prevalence_field_conditional_by_year <- 
    expand_grid(data_centered |>
                  distinct(year, year_centered),
                subfield = "hypothetical typical subfield", 
                journal = "hypothetical typical journal",
                type = "conditional",
                re_level = "field") |>
    tibble(res = pmap(list(subfield, journal, type, year_centered), 
                      est_prevalence, 
                      fit = fitted_model)) |>
    unnest(res) |>
    mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                               outcome == "behavioralproxy" ~ "Behavioral Proxy",
                               outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                               outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about Subjective States",
                               outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                               outcome == "cognitiveability" ~ "Cognitive Ability"),
           outcome = fct_relevel(outcome, 
                                 "Direct Behavioral",		
                                 "Behavioral Proxy",
                                 "Self-Report about Behavior",
                                 "Self-Report about Subjective States",
                                 "Neuro/Bio/Psychophys",
                                 "Cognitive Ability"))
  
  #write_rds(posterior_prevalence_field_year, "models/posterior_prevalence_field_year.rds")
  write_rds(posterior_prevalence_field_marginal_by_year,
            "models/posterior_prevalence_field_marginal_by_year.rds")
  write_rds(posterior_prevalence_field_conditional_by_year, 
            "models/posterior_prevalence_field_conditional_by_year.rds")
}

# plot
p_prevalence_and_trend_field_marginal <- ggplot() +
  geom_ribbon(data = posterior_prevalence_field_marginal_by_year, aes(year, ymin = prevalence_ci_lower, ymax = prevalence_ci_upper), fill = "skyblue", alpha = 0.5) +
  geom_smooth(data = posterior_prevalence_field_marginal_by_year, aes(year, prevalence_estimate),
              method = "lm", color = "black", size = 0.75, se = FALSE) +
  geom_point(data = data_summary_field, aes(year, proportion), size = 1) +
  theme_linedraw() +
  scale_x_continuous(breaks = c(2010, 2012, 2014, 2016, 2018, 2020, 2022)) +
  coord_cartesian(ylim = c(0,1)) +
  scale_y_continuous(labels = scales::label_percent()) + # , breaks = c(0, 0.05, 0.1, 0.25, 0.5, 1)
  ylab("Prevalence\n(Marginal Global Mean)") +
  xlab("Year") +
  facet_wrap( ~ outcome, ncol = 2)

p_prevalence_and_trend_field_marginal

quicksave("p_prevalence_and_trend_field_marginal", 9, 8)


p_prevalence_and_trend_field_conditional <- ggplot() +
  geom_ribbon(data = posterior_prevalence_field_conditional_by_year, aes(year, ymin = prevalence_ci_lower, ymax = prevalence_ci_upper), fill = "skyblue", alpha = 0.5) +
  geom_smooth(data = posterior_prevalence_field_conditional_by_year, aes(year, prevalence_estimate),
              method = "lm", color = "black", size = 0.75, se = FALSE) +
  geom_point(data = data_summary_field, aes(year, proportion), size = 1) +
  theme_linedraw() +
  scale_x_continuous(breaks = c(2010, 2012, 2014, 2016, 2018, 2020, 2022)) +
  coord_cartesian(ylim = c(0,1)) +
  scale_y_continuous(labels = scales::label_percent()) + # , breaks = c(0, 0.05, 0.1, 0.25, 0.5, 1)
  ylab("Prevalence\n(Conditional Global Mean)") +
  xlab("Year") +
  facet_wrap( ~ outcome, ncol = 2)

p_prevalence_and_trend_field_conditional

quicksave("p_prevalence_and_trend_field_conditional", 9, 8)

```

### Subfields

**Even more than the other chunks, this one takes time to run. Not run during dev. Change eval=TRUE to run.**

```{r fig.height=8, fig.width=12, eval=FALSE}

# calculate empirical means
data_summary_subfields <- data_centered |>
  pivot_longer(cols = c("directbehavioral", 
                        "behavioralproxy",
                        "selfreportsaboutbehavior",
                        "selfreportaboutsubjectivestate",
                        "neurobiopsychophys",
                        "cognitiveability"),
               names_to = "outcome",
               values_to = "used") |>
  group_by(subfield, year, outcome) |>
  summarize(proportion = mean(used)) |>
  mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                             outcome == "behavioralproxy" ~ "Behavioral Proxy",
                             outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                             outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about\nSubjective Experience",
                             outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                             outcome == "cognitiveability" ~ "Cognitive Ability"),
         outcome = fct_relevel(outcome, 
                               "Direct Behavioral",		
                               "Behavioral Proxy",
                               "Self-Report about Behavior",
                               "Self-Report about\nSubjective Experience",
                               "Neuro/Bio/Psychophys",
                               "Cognitive Ability"))

if(exists("models/posterior_prevalence_subfields_conditional_by_year.rds")){
  
  posterior_prevalence_subfields_conditional_by_year <-
    read_rds("models/posterior_prevalence_subfields_conditional_by_year.rds")
  
} else {
  
  posterior_prevalence_subfields_conditional_by_year <- 
    expand_grid(data_centered |>
                  distinct(year, year_centered, subfield),
                journal = "hypothetical typical journal",
                type = "conditional",
                re_level = "subfields") |>
    tibble(res = pmap(list(subfield, journal, type, year_centered), 
                      est_prevalence, 
                      fit = fitted_model)) |>
    unnest(res)  |>
    mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                               outcome == "behavioralproxy" ~ "Behavioral Proxy",
                               outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                               outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about/nSubjective Experience",
                               outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                               outcome == "cognitiveability" ~ "Cognitive Ability"),
           outcome = fct_relevel(outcome, 
                                 "Direct Behavioral",		
                                 "Behavioral Proxy",
                                 "Self-Report about Behavior",
                                 "Self-Report about\nSubjective Experience",
                                 "Neuro/Bio/Psychophys",
                                 "Cognitive Ability"))
  
  write_rds(posterior_prevalence_subfields_conditional_by_year, 
            "models/posterior_prevalence_subfields_conditional_by_year.rds")
}

# plot
p_prevalence_and_trend_subfields <- ggplot() +
  geom_ribbon(data = posterior_prevalence_subfields_conditional_by_year, aes(year, ymin = prevalence_ci_lower, ymax = prevalence_ci_upper), fill = "skyblue", alpha = 0.5) +
  geom_smooth(data = posterior_prevalence_subfields_conditional_by_year, aes(year, prevalence_estimate),
              method = "lm", color = "black", size = 0.75, se = FALSE) +
  geom_point(data = data_summary_subfields, aes(year, proportion), size = 1) +
  theme_linedraw() +
  #scale_x_continuous(breaks = c(2010, 2012, 2014, 2016, 2018, 2020, 2022)) +
  scale_x_continuous(breaks = c(2010, 2014, 2018, 2022)) +
  coord_cartesian(ylim = c(0,1)) +
  scale_y_continuous(labels = scales::label_percent()) + # , breaks = c(0, 0.05, 0.1, 0.25, 0.5, 1)
  ylab("Prevalence") +
  xlab("Year") +
  facet_grid(subfield ~ outcome)

p_prevalence_and_trend_subfields

quicksave("p_prevalence_and_trend_subfields", 12, 8)

```

## Combined table with summary conclusions

categorical conclusions for field, subfield, and journal levels based on prevalence category and trend (detectably increasing/decreasing, no detectable change)

```{r}

# join and clean up
posterior_prevalence_and_trends <- 
  full_join(posterior_prevalence, 
            posterior_trends,
            by = c("outcome", "label", "re_level", "type", "subfield", "journal")) |>
  mutate(prevalence_estimate = rnd(prevalence_estimate),
         prevalence_interval = paste0(rnd(prevalence_ci_lower), ", ", rnd(prevalence_ci_upper)),
         trend_estimate = rnd(trend_estimate),
         trend_interval = paste0(rnd(trend_ci_lower), ", ", rnd(trend_ci_upper))) |>
  select(re_level, label, outcome, 
         prevalence_estimate, prevalence_interval, prevalence_category, 
         trend_estimate, trend_interval, trend_category) |>
  arrange(desc(label), desc(outcome))

# save to disk
posterior_prevalence_and_trends |>
  filter(re_level %in% c("field", "subfields")) |>
  select(-re_level) |>
  write_csv("../../data/registered report/results/posterior_prevalence_and_trends_field_subfield.csv")

posterior_prevalence_and_trends |>
  filter(!re_level %in% c("field", "subfields")) |>
  select(-re_level) |>
  write_csv("../../data/registered report/results/posterior_prevalence_and_trends_journals.csv")

# print the table just for field and subfields
posterior_prevalence_and_trends |>
  filter(re_level %in% c("field", "subfields")) |>
  select(-re_level) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Correlations among the random effects

At the level of journals.

#### Prevalence

```{r fig.height=7.5, fig.width=7.5}

# extract correlations/covariances among the random effects
var_cors <- VarCorr(fitted_model)

# wrangle
var_cors_journal <- var_cors$`subfield:journal`$cor |>
  as.data.frame() |>
  rownames_to_column(var = "var")

var_cors_journal_intercept <- var_cors_journal |>
  filter(str_detect(var, "Intercept")) |>
  select(var, contains("Intercept") & contains("Estimate.")) |>
  mutate(var = str_remove(var, "_Intercept")) %>%
  rename_with(~ str_remove(., "Estimate.")) %>%
  rename_with(~ str_remove(., "_Intercept"))

# show_col(viridis::mako(25))
# viridis::mako(25)

# plot
cors_journal_intercept <- var_cors_journal_intercept |>
  rename(outcome = var,
         "Direct Behavioral" = directbehavioral, 
         "Behavioral Proxy" = behavioralproxy, 
         "Self-Report about Behavior" = selfreportsaboutbehavior, 
         "Self-Report about Subjective States" = selfreportaboutsubjectivestate, 
         "Neuro/Bio/Psychophys" = neurobiopsychophys, 
         "Cognitive Ability" = cognitiveability) |>
  mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                             outcome == "behavioralproxy" ~ "Behavioral Proxy",
                             outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                             outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about Subjective States",
                             outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                             outcome == "cognitiveability" ~ "Cognitive Ability")) 

cors_journal_intercept |>
  mutate_if(is.numeric, rnd) |>
  write_csv("../../data/registered report/results/cors_journal_intercept.csv")

# table
cors_journal_intercept |>
  mutate_if(is.numeric, rnd) |>
  kable(caption = "Correlations among random effects for prevalence at the journal level") |>
  kable_classic(full_width = FALSE)

p_cors_journal_intercept <- cors_journal_intercept |>
  column_to_rownames("outcome") |>
  ggcorrplot(method = "circle",
             #hc.order = TRUE,
             colors = c("#413E7EFF", "#DEF5E5FF", "#359EAAFF"),
             type = "full",
             outline.col = "grey20",
             ggtheme = ggplot2::theme_linedraw) + 
  ggtitle("Correlations among prevalences")

p_cors_journal_intercept 

quicksave("p_cors_journal_intercept", 7.5, 7.5)

```

#### Trend

What was correlation between the change in prevalences over time in the different modes of measurement? As one mode becomes more/less common, what happened for the others? 

```{r fig.height=7.5, fig.width=7.5}

# wrangle
var_cors_journal_slope <- var_cors_journal |>
  filter(str_detect(var, "_year_centered")) |>
  select(var, contains("_year_centered") & contains("Estimate.")) |>
  mutate(var = str_remove(var, "_year_centered")) %>%
  rename_with(~ str_remove(., "Estimate.")) %>%
  rename_with(~ str_remove(., "_year_centered"))

# show_col(viridis::mako(25))
# viridis::mako(25)

# plot
cors_journal_slope <- var_cors_journal_slope |> 
  rename(outcome = var,
         "Direct Behavioral" = directbehavioral, 
         "Behavioral Proxy" = behavioralproxy, 
         "Self-Report about Behavior" = selfreportsaboutbehavior, 
         "Self-Report about Subjective States" = selfreportaboutsubjectivestate, 
         "Neuro/Bio/Psychophys" = neurobiopsychophys, 
         "Cognitive Ability" = cognitiveability) |>
  mutate(outcome = case_when(outcome == "directbehavioral" ~ "Direct Behavioral",		
                             outcome == "behavioralproxy" ~ "Behavioral Proxy",
                             outcome == "selfreportsaboutbehavior" ~ "Self-Report about Behavior",
                             outcome == "selfreportaboutsubjectivestate" ~ "Self-Report about Subjective States",
                             outcome == "neurobiopsychophys" ~ "Neuro/Bio/Psychophys",
                             outcome == "cognitiveability" ~ "Cognitive Ability")) 

cors_journal_slope |>
  mutate_if(is.numeric, rnd) |>
  write_csv("../../data/registered report/results/cors_journal_slope.csv")

# table
cors_journal_slope |>
  mutate_if(is.numeric, rnd) |>
  kable(caption = "Correlations among random effects for trend at the subfield level") |>
  kable_classic(full_width = FALSE)

p_cors_journal_slope <- cors_journal_slope |>
  column_to_rownames("outcome") |>
  ggcorrplot(method = "circle",
             #hc.order = TRUE,
             colors = c("#413E7EFF", "#DEF5E5FF", "#359EAAFF"), 
             type = "full",
             outline.col = "grey20",
             ggtheme = ggplot2::theme_linedraw) + 
  ggtitle("Correlations among trends")

p_cors_journal_slope

quicksave("p_cors_journal_slope", 7.5, 7.5)

```

# Watermark simulated data plots 

```{r fig.height=6, fig.width=5}

library(grid)

watermark <- function(fontsize = 20){
  annotation_custom(
    grob = textGrob(label = "Simulated data",
                    gp = gpar(fontsize = fontsize, 
                              col = "red", 
                              alpha = 0.5), 
                    rot = 30),
    xmin = -Inf, xmax = Inf,
    ymin = -Inf, ymax = Inf
  )
}

```

## Subfields

```{r fig.height=6, fig.width=11}

p_prevalence_subfields + watermark(10)

quicksave("p_prevalence_subfields_watermark", 11, 6)

p_trend_subfields + watermark(10)

quicksave("p_trend_subfields_watermark", 11, 6)

```

## Journals

```{r fig.height=12, fig.width=10}

p_prevalence_journals + watermark(30)

quicksave("p_prevalence_journals_watermark", 12, 10)


p_trend_journals + watermark(30)

quicksave("p_trend_journals_watermark", 12, 10)

```

## Prevalences + trends

```{r fig.height=8, fig.width=9}

p_prevalence_and_trend_field_marginal + watermark()

quicksave("p_prevalence_and_trend_field_marginal_watermark", 9, 8)


p_prevalence_and_trend_field_conditional + watermark()

quicksave("p_prevalence_and_trend_field_conditional_watermark", 9, 8)

```

**Even more than the other chunks, this one takes time to run. Not run during dev. Change eval=TRUE to run.**

```{r fig.height=8, fig.width=12, eval=FALSE}

p_prevalence_and_trend_subfields + watermark()

quicksave("p_prevalence_and_trend_subfields_watermark", 12, 8)

```

## Correlations

```{r fig.height=7.5, fig.width=7.5}

p_cors_journal_intercept + watermark(30)

quicksave("p_cors_journal_intercept_watermark", 7.5, 7.5)


p_cors_journal_slope + watermark(30)

quicksave("p_cors_journal_slope_watermark", 7.5, 7.5)

```

# Session info

```{r}

sessionInfo()

```


