---
title: "Measurement trends in psychology"
subtitle: "Analysis"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# TODO

- add pairwise comparisons for subfields?
- think about priors more
- think about model diagnostics more
- Extracted trends are currently identical across levels of the random effect, which can't be right. Fix existing code or write a manual version that estimates trend from multiple estimated means? 
- table of correlations among residuals could star the estimates with intervals that exclude 0. some commented out code attempting this.


control = list(adapt_delta = .99), 
  iter = 2000, 
  warmup = 1000,  
  chains = 4, 
  cores = 4  

```{r setup, include=FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

```

```{r}

library(dplyr)
library(tidyr)
library(tibble)
library(ggplot2)
library(scales)
library(ggstance)
library(brms)
library(tidybayes)
library(emmeans)
#library(broom)
library(purrr)
library(janitor)
library(knitr)
library(kableExtra)
library(forcats)
library(ggcorrplot)


dir.create("models")

```

# Data

## Simulate data

We will have two raters and they can either (a) score each article so that each one is scored twice, or (b) they could overlap eg 10% of articles for double scoring, so that more articles can be scored in total. Any input on this?

Each rater will score each measurement type as either present (1) or absent (0) in that article. There are 6 measurement types according to our scoring, and we see these categories as exhaustive. There will probably be 6 subfields and 5 journals per subfield. 

In the case of disagreements, should we solve this in data processing (get agreement between the authors/round down/round up) or model it? 

The total number of articles to be scored is still to be determined, as we don't know the average extraction time or the total resources available to us here (1 or 2 RAs or masters students or a mix).

When a journal has not existed for all years in the range, should we still extract the same number of articles from the years that do exist, or should we extract a proportionate number of articles (so the articles per year is stable)?

```{r}

set.seed(42)

n_articles_per_journal <- 15 # current estimate
n_journals_per_subfield <- 5
n_subfields <- 6

n_articles_total <- n_articles_per_journal * n_journals_per_subfield * n_subfields

data_simulated <-
  tibble(
    article_id = seq(from = 1, 
                     to = n_articles_total, 
                     by = 1),
    year = sample(x = 2009:2023,  # year range 
                  size = n_articles_total, 
                  replace = TRUE),
    directbehavioral = rbinom(n = n_articles_total,
                              size = 1, # values between 0 and 1
                              prob = .05), # probability of a given study containing such a measure
    behavioralproxy = rbinom(n = n_articles_total,
                             size = 1, # values between 0 and 1
                             prob = .1), # probability of a given study containing such a measure
    selfreportsaboutbehavior = rbinom(n = n_articles_total,
                                      size = 1, # values between 0 and 1
                                      prob = .1), # probability of a given study containing such a measure
    mixed = rbinom(n = n_articles_total,
                   size = 1, # values between 0 and 1
                   prob = .1), # probability of a given study containing such a measure
    selfreport = c(rbinom(n = n_articles_total/2,
                          size = 1, # values between 0 and 1
                          prob = .95), # probability of a given study containing such a measure
                   rbinom(n = n_articles_total/2,
                          size = 1, # values between 0 and 1
                          prob = .70)),
    neurophys = rbinom(n = n_articles_total,
                       size = 1, # values between 0 and 1
                       prob = .1), # probability of a given study containing such a measure
    cognitiveability = rbinom(n = n_articles_total,
                              size = 1, # values between 0 and 1
                              prob = .1) # probability of a given study containing such a measure
  ) |>
  mutate(article_id = as.factor(paste0("doi_", article_id)),
         subfield = c(rep("General", n_articles_per_journal * n_journals_per_subfield),
                      rep("Cognitive", n_articles_per_journal * n_journals_per_subfield),
                      rep("Clinical", n_articles_per_journal * n_journals_per_subfield),
                      rep("Developmental", n_articles_per_journal * n_journals_per_subfield),
                      rep("I/O", n_articles_per_journal * n_journals_per_subfield),
                      rep("Social/Personality", n_articles_per_journal * n_journals_per_subfield)),
         subfield = as.factor(subfield),
         journal = paste(subfield, "journal", seq(from = 1, to = 5)))


# save for reproducibility
if(!file.exists("models/data_simulated.csv")){
  write_csv(data_simulated, "models/data_simulated.csv")
}

```

### Check

```{r}

data_simulated |>
  count(subfield, journal)

data_simulated |>
  summarize(mean_directbehavioral = mean(directbehavioral),
            mean_behavioralproxy = mean(behavioralproxy),
            mean_selfreportsaboutbehavior = mean(selfreportsaboutbehavior),
            mean_mixed = mean(mixed),
            mean_selfreport = mean(selfreport),
            mean_neurophys = mean(neurophys),
            mean_cognitiveability = mean(cognitiveability)) |>
  mutate_all(round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

data_simulated |>
  group_by(subfield, journal) |>
  summarize(mean_directbehavioral = mean(directbehavioral),
            mean_behavioralproxy = mean(behavioralproxy),
            mean_selfreportsaboutbehavior = mean(selfreportsaboutbehavior),
            mean_mixed = mean(mixed),
            mean_selfreport = mean(selfreport),
            mean_neurophys = mean(neurophys),
            mean_cognitiveability = mean(cognitiveability)) |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

## Real data

```{r}

# simulated data will be replaced with real data after collection
# data_processed <- read_csv("../../data/processed/data_processed.csv")

```

# Analyze

## Fit model

```{r}

# # real data
# data_centered <- data_processed |>
#   mutate(year_centered = year - 2016)

# simulated data for development
data_centered <- data_simulated |>
  mutate(year_centered = year - 2016)

# needed later
outcome_measures <- c("directbehavioral",
                      "behavioralproxy",
                      "selfreportsaboutbehavior",
                      "mixed",
                      "selfreport",
                      "neurophys",
                      "cognitiveability")

year_centered_values <- data_centered |>
  distinct(year_centered) |>
  pull(year_centered)


# set seed
set.seed(42)

# fit model
fitted_model <- brm(
  formula = 
    bf(formula = directbehavioral ~         1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal), 
       family = bernoulli(link = "logit")) +
    bf(formula = behavioralproxy ~          1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal), 
       family = bernoulli(link = "logit")) +
    bf(formula = selfreportsaboutbehavior ~ 1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal), 
       family = bernoulli(link = "logit")) +
    bf(formula = mixed ~                    1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal), 
       family = bernoulli(link = "logit")) +
    bf(formula = selfreport ~               1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal), 
       family = bernoulli(link = "logit")) +
    bf(formula = neurophys ~                1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal), 
       family = bernoulli(link = "logit")) +
    bf(formula = cognitiveability ~         1 + year_centered + (1 + year_centered | p | subfield) + (1 + year_centered | q | subfield:journal), 
       family = bernoulli(link = "logit")),
  data = data_centered,
  cores = parallel::detectCores(),
  file = "models/fitted_model"
)

```


```{r eval=FALSE, include=FALSE}

fitted_model
#pp_check(fitted_model, ndraws = 100, resp = "usesdirectbehavioral")

plot(fitted_model, comparisons = TRUE)

```

## Correlations among residuals

### Subfields

#### Prevalence

```{r}

# extract residual correlations/covariances
var_cors <- VarCorr(fitted_model)

# wrangle the residual correlations at the subfield level of the random effect
var_cors_field <- var_cors$subfield$cor |>
  as.data.frame() |>
  rownames_to_column(var = "var")

# extract those for the prevalences' point estimates
var_cors_field_intercept <- var_cors_field |>
  filter(str_detect(var, "Intercept")) |>
  select(var, contains("Intercept") & contains("Estimate.")) |>
  mutate_if(is.numeric, round_half_up, digits = 2) |>
  mutate(var = str_remove(var, "_Intercept")) %>%
  rename_with(~ str_remove(., "Estimate.")) %>%
  rename_with(~ str_remove(., "_Intercept"))

# var_cors_field_intercept_upper <- var_cors_field |>
#   filter(str_detect(var, "Intercept")) |>
#   select(var, contains("Intercept") & contains("Q97.5.")) |>
#   mutate(var = str_remove(var, "_Intercept")) %>%
#   rename_with(~ str_remove(., "Q97.5.")) %>%
#   rename_with(~ str_remove(., "_Intercept")) %>%
#   mutate(across(where(is.numeric), ~ if_else(. < 0, 1, 0)))
# 
# var_cors_field_intercept_lower <- var_cors_field |>
#   filter(str_detect(var, "Intercept")) |>
#   select(var, contains("Intercept") & contains("Q2.5.")) |>
#   mutate(var = str_remove(var, "_Intercept")) %>%
#   rename_with(~ str_remove(., "Q2.5.")) %>%
#   rename_with(~ str_remove(., "_Intercept")) %>%
#   mutate(across(where(is.numeric), ~ if_else(. > 0, 1, 0)))
# 
# result <- var_cors_field_intercept_upper %>%
#   mutate(across(
#     .cols = where(is.numeric),
#     .fns = ~ if_else(. == 1 | var_cors_field_intercept_lower[[cur_column()]] == 1, "*", "")
#   ))

# print table
var_cors_field_intercept |>
  kable(caption = "Correlations among residuals for prevalences at the subfield level") |>
  kable_classic(full_width = FALSE)


# show_col(viridis::mako(25))
# viridis::mako(25)

p_cors_field_intercept <- var_cors_field_intercept |> 
  column_to_rownames("var") |>
  ggcorrplot(hc.order = TRUE, 
             method = "circle",
             colors = c("#413E7EFF", "#DEF5E5FF", "#359EAAFF"), 
             type = "full",
             outline.col = "grey20",
             ggtheme = ggplot2::theme_linedraw) 

p_cors_field_intercept

```

#### Trend

```{r}

var_cors_field_slope <- var_cors_field |>
  filter(str_detect(var, "_year_centered")) |>
  select(var, contains("_year_centered") & contains("Estimate.")) |>
  mutate_if(is.numeric, round_half_up, digits = 2) |>
  mutate(var = str_remove(var, "_year_centered")) %>%
  rename_with(~ str_remove(., "Estimate.")) %>%
  rename_with(~ str_remove(., "_year_centered"))

var_cors_field_slope |>
  kable(caption = "Correlations among residuals for trend at the subfield level") |>
  kable_classic(full_width = FALSE)

corr_field_slope <- 

# show_col(viridis::mako(25))
# viridis::mako(25)
  
p_cors_field_slope <- var_cors_field_slope |> 
  column_to_rownames("var") |>
  ggcorrplot(hc.order = TRUE, 
             method = "circle",
             colors = c("#413E7EFF", "#DEF5E5FF", "#359EAAFF"), 
             type = "full",
             outline.col = "grey20",
             ggtheme = ggplot2::theme_linedraw)

p_cors_field_slope

```

### Journals

#### Prevalence \TODO

still have to decide whether to extract recors at the journal or subfield level. former might have more variance and nuance, latter has less risk of overfitting. fit both and WAIC?

```{r}

var_cors_journal <- var_cors$`subfield:journal`$cor |>
  as.data.frame() |>
  rownames_to_column(var = "var")

var_cors_journal_intercept <- var_cors_journal |>
  filter(str_detect(var, "Intercept")) |>
  select(var, contains("Intercept") & contains("Estimate.")) |>
  mutate_if(is.numeric, round_half_up, digits = 2) |>
  mutate(var = str_remove(var, "_Intercept")) %>%
  rename_with(~ str_remove(., "Estimate.uses")) %>%
  rename_with(~ str_remove(., "_Intercept"))

var_cors_journal_intercept |>
  kable(caption = "Correlations among residuals for prevalences at the journal level") |>
  kable_classic(full_width = FALSE)

```

#### Trend \TODO

(possibly needed)


## Extract estimates

Resource used: https://www.andrewheiss.com/blog/2021/11/10/ame-bayes-re-guide/

### Prevalence

```{r}

# field
est_prevalence_grandmean <- function(outcome, fit){
  fit |>
    emmeans(specs = ~ 1,
            at = list(year_centered = 0),
            epred = TRUE,
            re_formula = NA,
            allow_new_levels = FALSE,
            resp = outcome) |>
    summary() |>
    mutate(outcome = outcome) |>
    select(prevalence_estimate = emmean,
           prevalence_ci_lower = lower.HPD,
           prevalence_ci_upper = upper.HPD)
}

res_prevalence_field <- 
  expand_grid(outcome = outcome_measures) |>
  tibble(res = pmap(list(outcome), 
                    est_prevalence_grandmean, 
                    fit = fitted_model)) |>
  unnest(res) |>
  mutate(re_level = "field",
         subfield = "hypothetical typical subfield", 
         journal = "hypothetical typical journal")



# estimate prevalence for either an existing subfield and journal, or an existing subfield and hypothetical journal, or hypothetical subfield and journal
est_prevalence <- function(outcome, subfield, journal, fit){
  fit |>
    emmeans(specs = ~ 1,
            at = list(year_centered = 0,
                      subfield = subfield,
                      journal = journal),
            resp = outcome,
            epred = TRUE,
            re_formula = NULL,
            allow_new_levels = TRUE,
            sample_new_levels = "uncertainty",
            rg.limit = 40000)  |>
    summary() |>
    select(prevalence_estimate = emmean,
           prevalence_ci_lower = lower.HPD,
           prevalence_ci_upper = upper.HPD)
}

helper_function_prevalence <- function(outcome, subfield, journal, fit){
  tibble(outcome = outcome,
         subfield = subfield,
         journal = journal) |>
    mutate(res = pmap(list(outcome,
                           subfield,
                           journal,
                           list(fit)),
                      est_prevalence)) |>
    unnest(cols = c(res)) |>
    select(-outcome, -subfield, -journal)
}

# subfields
res_prevalence_subfields <- 
  expand_grid(outcome = outcome_measures,
              data_centered |>
                distinct(subfield),
              journal = "hypothetical typical journal") |>
  mutate(res = pmap(list(outcome, subfield, journal), 
                    helper_function_prevalence, 
                    fit = fitted_model)) |>
  unnest() |>
  mutate(re_level = "subfields")

# journals
res_prevalence_journals <- 
  expand_grid(outcome = outcome_measures,
              data_centered |>
                distinct(subfield, journal)) |>
  mutate(res = pmap(list(outcome, subfield, journal), 
                    helper_function_prevalence, 
                    fit = fitted_model)) |>
  unnest() |>
  mutate(re_level = "journals")

# combine
res_prevalence <- 
  bind_rows(res_prevalence_field,
            res_prevalence_subfields,
            res_prevalence_journals) |>
  mutate(label = case_when(re_level == "field" ~ "Psychology",
                           re_level == "subfields" & journal == "hypothetical typical journal" ~ subfield,
                           journal != "hypothetical typical journal" & !is.na(journal) ~ journal)) |>
  mutate(label = fct_relevel(
    label,
    "Psychology", 
    
    "General", 
    "General journal 2", 
    "General journal 3", 
    "General journal 4", 
    "General journal 5", 
    "General journal 1", 
    
    "Cognitive", 
    "Cognitive journal 2", 
    "Cognitive journal 3", 
    "Cognitive journal 4", 
    "Cognitive journal 5", 
    "Cognitive journal 1", 
    
    "Clinical", 
    "Clinical journal 3", 
    "Clinical journal 4", 
    "Clinical journal 5", 
    "Clinical journal 1", 
    "Clinical journal 2", 
    
    "Developmental", 
    "Developmental journal 4", 
    "Developmental journal 5", 
    "Developmental journal 1", 
    "Developmental journal 2", 
    "Developmental journal 3", 
    
    "I/O", 
    "I/O journal 5", 
    "I/O journal 1", 
    "I/O journal 2", 
    "I/O journal 3", 
    "I/O journal 4", 
    
    "Social/Personality", 
    "Social/Personality journal 1", 
    "Social/Personality journal 2", 
    "Social/Personality journal 3", 
    "Social/Personality journal 4", 
    "Social/Personality journal 5"                   
  ),
  label = fct_rev(label)) |>
  mutate(outcome = case_when(outcome == "directbehavioral" ~ "Behavioral measure",
                             outcome == "behavioralproxy" ~ "Behavioral proxy",
                             outcome == "selfreportsaboutbehavior" ~ "Self-report about behavior",
                             outcome == "mixed" ~ "Mixed self-report about behavior",
                             outcome == "selfreport" ~ "Self-report measure",
                             outcome == "cognitiveability" ~ "Cognitive ability",
                             outcome == "neurophys" ~ "Neurophysiological",
                             TRUE ~ outcome),
         outcome = fct_relevel(outcome,
                               "Behavioral measure",
                               "Behavioral proxy",
                               "Self-report about behavior",
                               "Mixed self-report about behavior",
                               "Self-report measure",
                               "Cognitive ability",
                               "Neurophysiological"),
         outcome = fct_rev(outcome),
         subfield = fct_relevel(subfield,
                                "hypothetical typical subfield",
                                "Clinical",
                                "Cognitive",
                                "Developmental",
                                "General",
                                "I/O",
                                "Social/Personality")) |>
  select(outcome, label, re_level, subfield, journal, 
         prevalence_estimate, prevalence_ci_lower, prevalence_ci_upper) |>
  arrange(outcome, subfield)


# print table
res_prevalence |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

#### Field + Subfields

```{r fig.height=4.5, fig.width=9}

# p_prevalence_subfields <- res_prevalence |>
#   filter(re_level != "journals") |>
#   ggplot(aes(prevalence_estimate, label, color = outcome)) +
#   # geom_rect(aes(xmin = 0.00, xmax = 0.05, ymin = -Inf, ymax = Inf, color = NULL),
#   #           fill = "grey70", alpha = 0.05) +
#   # geom_rect(aes(xmin = 0.05, xmax = 0.10, ymin = -Inf, ymax = Inf, color = NULL),
#   #           fill = "grey77", alpha = 0.05) +
#   # geom_rect(aes(xmin = 0.10, xmax = 0.25, ymin = -Inf, ymax = Inf, color = NULL),
#   #           fill = "grey85", alpha = 0.05) +
#   # geom_rect(aes(xmin = 0.25, xmax = 0.50, ymin = -Inf, ymax = Inf, color = NULL),
#   #           fill = "grey92", alpha = 0.05) +
#   # geom_rect(aes(xmin = 0.50, xmax = 1.00, ymin = -Inf, ymax = Inf, color = NULL),
#   #           fill = "grey99", alpha = 0.05) +
#   geom_linerangeh(aes(xmin = prevalence_ci_lower, xmax = prevalence_ci_upper), position = position_dodge(width = .8)) +
#   geom_point(position = position_dodge(width = .8)) +
#   coord_cartesian(xlim = c(0, 1)) +
#   theme_linedraw() +
#   ylab("") +
#   xlab("Prevalence") +
#   scale_x_continuous(labels = scales::label_percent(), breaks = c(0, 0.05, 0.1, 0.25, 0.5, 1)) +
#   guides(color = guide_legend(title = "Measure type",
#                               reverse = TRUE))


p_prevalence_subfields <- res_prevalence |>
  filter(re_level != "journals") |>
  ggplot(aes(prevalence_estimate, label, color = outcome)) +
  geom_linerangeh(aes(xmin = prevalence_ci_lower, xmax = prevalence_ci_upper), position = position_dodge(width = .8)) +
  geom_point(position = position_dodge(width = .8)) +
  coord_cartesian(xlim = c(0, 1)) +
  theme_linedraw() +
  ylab("") +
  xlab("Prevalence") +
  scale_x_continuous(labels = scales::label_percent(), breaks = c(0, 0.05, 0.1, 0.25, 0.5, 1)) +
  guides(color = guide_legend(title = "Measure type",
                              reverse = TRUE))

p_prevalence_subfields

```

#### Journals

```{r fig.height=12, fig.width=9}

p_prevalence_journals <- res_prevalence |>
  filter(re_level == "journals") |>
  ggplot(aes(prevalence_estimate, label, color = outcome)) +
  geom_linerangeh(aes(xmin = prevalence_ci_lower, xmax = prevalence_ci_upper), position = position_dodge(width = .8)) +
  geom_point(position = position_dodge(width = .8)) +
  coord_cartesian(xlim = c(0, 1)) +
  theme_linedraw() +
  ylab("") +
  xlab("Prevalence") +
  guides(color = guide_legend(title = "Measure type",
                              reverse = TRUE))

p_prevalence_journals

```

### Trend

```{r}

# field
est_trend_grandmean <- function(fit, outcome){
  fit |>
    emtrends(specs = ~ year_centered,
             var = "year_centered",
             at = list(year_centered = 0),
             epred = TRUE,
             re_formula = NA,
             allow_new_levels = FALSE,
             resp = outcome) |>
    summary() |>
    mutate(outcome = outcome) |>
    select(trend_estimate = year_centered.trend,
           trend_ci_lower = lower.HPD,
           trend_ci_upper = upper.HPD)
}

res_trend_field <- 
  expand_grid(outcome = outcome_measures) |>
  tibble(res = pmap(list(outcome), 
                    est_trend_grandmean, 
                    fit = fitted_model)) |>
  unnest(res) |>
  mutate(re_level = "field",
         subfield = "hypothetical typical subfield", 
         journal = "hypothetical typical journal")


# estimate prevalence for either an existing subfield and journal, or an existing subfield and hypothetical journal, or hypothetical subfield and journal
est_trend <- function(outcome, subfield, journal, fit){
  fit |>
    emtrends(specs = ~ 1,
             var = "year_centered",
             at = list(year_centered = 0,
                       subfield = subfield,
                       journal = journal),
             epred = TRUE,
             re_formula = NA,
             allow_new_levels = TRUE,
             sample_new_levels = "uncertainty",
             resp = outcome) |>
    summary() |>
    mutate(outcome = outcome) |>
    select(trend_estimate = year_centered.trend,
           trend_ci_lower = lower.HPD,
           trend_ci_upper = upper.HPD)
}

helper_function_trend <- function(outcome, subfield, journal, fit){
  tibble(outcome = outcome,
         subfield = subfield,
         journal = journal) |>
    mutate(res = pmap(list(outcome,
                           subfield,
                           journal,
                           list(fit)),
                      est_trend)) |>
    unnest(cols = c(res)) |>
    select(-outcome, -subfield, -journal)
}

# subfields
res_trend_subfields <- 
  expand_grid(outcome = outcome_measures,
              data_centered |>
                distinct(subfield),
              journal = "hypothetical typical journal") |>
  mutate(res = pmap(list(outcome, subfield, journal), 
                    helper_function_trend, 
                    fit = fitted_model)) |>
  unnest() |>
  mutate(re_level = "subfields")

# journals
res_trend_journals <- 
  expand_grid(outcome = outcome_measures,
              data_centered |>
                distinct(subfield, journal)) |>
  mutate(res = pmap(list(outcome, subfield, journal), 
                    helper_function_trend, 
                    fit = fitted_model)) |>
  unnest() |>
  mutate(re_level = "journals")

# combine
res_trends <- 
  bind_rows(res_trend_field,
            res_trend_subfields,
            res_trend_journals) |>
  mutate(subfield = ifelse(is.na(subfield), "", subfield),
         journal = ifelse(is.na(journal), "", journal)) |>
  mutate(label = case_when(re_level == "field" ~ "Psychology",
                           re_level == "subfields" & journal == "hypothetical typical journal" ~ subfield,
                           journal != "hypothetical typical journal" & !is.na(journal) ~ journal)) |>
  mutate(label = fct_relevel(
    label,
    "Psychology", 

    "General", 
    "General journal 2", 
    "General journal 3", 
    "General journal 4", 
    "General journal 5", 
    "General journal 1", 
    
    "Cognitive", 
    "Cognitive journal 2", 
    "Cognitive journal 3", 
    "Cognitive journal 4", 
    "Cognitive journal 5", 
    "Cognitive journal 1", 
    
    "Clinical", 
    "Clinical journal 3", 
    "Clinical journal 4", 
    "Clinical journal 5", 
    "Clinical journal 1", 
    "Clinical journal 2", 
    
    "Developmental", 
    "Developmental journal 4", 
    "Developmental journal 5", 
    "Developmental journal 1", 
    "Developmental journal 2", 
    "Developmental journal 3", 
    
    "I/O", 
    "I/O journal 5", 
    "I/O journal 1", 
    "I/O journal 2", 
    "I/O journal 3", 
    "I/O journal 4", 
    
    "Social/Personality", 
    "Social/Personality journal 1", 
    "Social/Personality journal 2", 
    "Social/Personality journal 3", 
    "Social/Personality journal 4", 
    "Social/Personality journal 5"                   
  ),
  label = fct_rev(label)) |>
  mutate(outcome = case_when(outcome == "directbehavioral" ~ "Behavioral measure",
                             outcome == "behavioralproxy" ~ "Behavioral proxy",
                             outcome == "selfreportsaboutbehavior" ~ "Self-report about behavior",
                             outcome == "mixed" ~ "Mixed self-report about behavior",
                             outcome == "selfreport" ~ "Self-report measure",
                             outcome == "cognitiveability" ~ "Cognitive ability",
                             outcome == "neurophys" ~ "Neurophysiological",
                             TRUE ~ outcome),
         outcome = fct_relevel(outcome,
                               "Behavioral measure",
                               "Behavioral proxy",
                               "Self-report about behavior",
                               "Mixed self-report about behavior",
                               "Self-report measure",
                               "Cognitive ability",
                               "Neurophysiological"),
         outcome = fct_rev(outcome),
         subfield = fct_relevel(subfield,
                                "hypothetical typical subfield",
                                "Clinical",
                                "Cognitive",
                                "Developmental",
                                "General",
                                "I/O",
                                "Social/Personality")) |>
  select(outcome, label, re_level, subfield, journal, 
         trend_estimate, trend_ci_lower, trend_ci_upper) |>
  mutate(detectable = case_when(trend_ci_lower > 0 ~ TRUE,
                                trend_ci_upper < 0 ~ TRUE,
                                TRUE ~ FALSE)) |>
  arrange(outcome, subfield)

# print table
res_trends |>
  mutate_if(is.numeric, round_half_up, digits = 3) |>
  kable() |>
  kable_classic(full_width = FALSE)

```

#### Field + Subfields

```{r fig.height=4.5, fig.width=9}

p_trend_subfields <- res_trends |>
  filter(re_level != "journals") |>
  ggplot(aes(trend_estimate, label, color = outcome)) +
  geom_linerangeh(aes(xmin = trend_ci_lower, xmax = trend_ci_upper), position = position_dodge(width = .8)) +
  geom_point(position = position_dodge(width = .8)) +
  coord_cartesian(xlim = c(-.1, .1)) +
  theme_linedraw() +
  ylab("") +
  xlab("Trend (change per year)") +
  scale_x_continuous(labels = scales::label_percent(), breaks = breaks_pretty()) +
  guides(color = guide_legend(title = "Measure type",
                              reverse = TRUE))

p_trend_subfields

```

#### Journals

```{r fig.height=12, fig.width=9}

p_trend_journals <- res_trends |>
  filter(re_level == "journals") |>
  ggplot(aes(trend_estimate, label, color = outcome)) +
  geom_linerangeh(aes(xmin = trend_ci_lower, xmax = trend_ci_upper), position = position_dodge(width = .8)) +
  geom_point(position = position_dodge(width = .8)) +
  coord_cartesian(xlim = c(-.1, .1)) +
  theme_linedraw() +
  ylab("") +
  xlab("Trend (change per year)") +
  scale_x_continuous(labels = scales::label_percent(), breaks = breaks_pretty()) +
  guides(color = guide_legend(title = "Measure type",
                              reverse = TRUE))

p_trend_journals

```

## Plot prevalences and trends 

### Field

```{r fig.height=8, fig.width=9}

# calculate empricial means
data_summary_field <- data_centered |>
  pivot_longer(cols = c("directbehavioral", 
                        "behavioralproxy",
                        "selfreportsaboutbehavior",
                        "mixed",
                        "selfreport",
                        "neurophys",
                        "cognitiveability"),
               names_to = "outcome",
               values_to = "used") |>
  group_by(year, outcome) |>
  summarize(proportion = mean(used))

# adjust the previously used function to fit for specific values of year_centered
est_prevalence_grandmean_year <- function(outcome, year_centered, fit){
  fit |>
    emmeans(specs = ~ 1,
            at = list(year_centered = year_centered),
            epred = TRUE,
            re_formula = NA,
            allow_new_levels = FALSE,
            resp = outcome) |>
    summary() |>
    select(prevalence_estimate = emmean,
           prevalence_ci_lower = lower.HPD,
           prevalence_ci_upper = upper.HPD)
}

res_prevalence_field_year <- 
  expand_grid(outcome = outcome_measures,
              year_centered = year_centered_values) |>
  mutate(res = pmap(list(outcome,
                         year_centered),
                    est_prevalence_grandmean_year,
                    fit = fitted_model)) |>
  unnest(res) |>
  mutate(re_level = "field",
         subfield = "hypothetical typical subfield", 
         journal = "hypothetical typical journal") |>
  left_join(data_centered |>
              distinct(year, year_centered),
            by = "year_centered")


# plot
p_years_field <- ggplot() +
  geom_ribbon(data = res_prevalence_field_year, aes(year, ymin = prevalence_ci_lower, ymax = prevalence_ci_upper), fill = "skyblue", alpha = 0.5) +
  geom_smooth(data = res_prevalence_field_year, aes(year, prevalence_estimate),
              method = "lm", color = "black", size = 0.75, se = FALSE) +
  geom_point(data = data_summary_field, aes(year, proportion), size = 1) +
  theme_linedraw() +
  scale_x_continuous(breaks = c(2010, 2012, 2014, 2016, 2018, 2020, 2022)) +
  coord_cartesian(ylim = c(0,1)) +
  scale_y_continuous(labels = scales::label_percent()) + # , breaks = c(0, 0.05, 0.1, 0.25, 0.5, 1)
  ylab("Prevalence") +
  xlab("Year") +
  facet_wrap( ~ outcome, ncol = 2)

p_years_field

```

### Subfields

```{r}

# calculate empirical means
data_summary_subfields <- data_centered |>
  pivot_longer(cols = c("directbehavioral", 
                        "behavioralproxy",
                        "selfreportsaboutbehavior",
                        "mixed",
                        "selfreport",
                        "neurophys",
                        "cognitiveability"),
               names_to = "outcome",
               values_to = "used") |>
  group_by(subfield, year, outcome) |>
  summarize(proportion = mean(used)) |>
  pivot_wider(names_from = outcome,
              values_from = proportion)

# adjust the previously used function to fit for specific values of year_centered
est_prevalence_subfield_year <- function(outcome, subfield, journal, year_centered, fit){
  fit |>
    emmeans(specs = ~ 1,
            at = list(year_centered = year_centered,
                      subfield = subfield,
                      journal = journal),
            epred = TRUE,
            re_formula = NULL,
            allow_new_levels = TRUE,
            sample_new_levels = "uncertainty",
            rg.limit = 40000,
            resp = outcome) |>
    summary() |>
    select(prevalence_estimate = emmean,
           prevalence_ci_lower = lower.HPD,
           prevalence_ci_upper = upper.HPD)
}


res_prevalence_subfield_year <- 
  expand_grid(outcome = outcome_measures,
              data_centered |>
                distinct(subfield),
              journal = "hypothetical typical journal",
              year_centered = year_centered_values) |>
  mutate(res = pmap(list(outcome,
                         subfield,
                         journal,
                         year_centered),
                    est_prevalence_subfield_year,
                    fit = fitted_model)) |>
  unnest(res) |>
  mutate(re_level = "subfields") |>
  left_join(data_centered |>
              distinct(year, year_centered),
            by = "year_centered")

# plot
p_years_subfields <- ggplot() +
  geom_ribbon(data = res_prevalence_field_year, aes(year, ymin = prevalence_ci_lower, ymax = prevalence_ci_upper), fill = "skyblue", alpha = 0.5) +
  geom_smooth(data = res_prevalence_field_year, aes(year, prevalence_estimate),
              method = "lm", color = "black", size = 0.75, se = FALSE) +
  geom_point(data = data_summary_field, aes(year, proportion), size = 1) +
  theme_linedraw() +
  #scale_x_continuous(breaks = c(2010, 2012, 2014, 2016, 2018, 2020, 2022)) +
  scale_x_continuous(breaks = c(2010, 2014, 2018, 2022)) +
  coord_cartesian(ylim = c(0,1)) +
  scale_y_continuous(labels = scales::label_percent()) + # , breaks = c(0, 0.05, 0.1, 0.25, 0.5, 1)
  ylab("Prevalence") +
  xlab("Year") +
  facet_grid(subfield ~ outcome)

```

### Watermark simulated data plots 

```{r fig.height=6, fig.width=5}

library(grid)

watermark <- function(fontsize = 20){
  annotation_custom(
    grob = textGrob(label = "Simulated data",
                    gp = gpar(fontsize = fontsize, 
                              col = "red", 
                              alpha = 0.5), 
                    rot = 30),
    xmin = -Inf, xmax = Inf,
    ymin = -Inf, ymax = Inf
  )
}

```

#### Residual correlations

```{r}

p_cors_field_intercept + watermark(30)

p_cors_field_slope + watermark(30)

# p_cors_journal_intercept + watermark(30)
# 
# p_cors_journal_slope + watermark(30)

```

#### Prevalences

```{r fig.height=4.5, fig.width=9}

p_prevalence_subfields + watermark(30)

p_trend_subfields + watermark(30)

```

#### Trends

```{r fig.height=12, fig.width=9}

p_prevalence_journals + watermark(30)

p_trend_journals + watermark(30)

```

#### Prevalences + trends

```{r fig.height=8, fig.width=9}

p_years_field + watermark()

```

```{r fig.height=8, fig.width=9}

p_years_subfields + watermark()

```

# Session info

```{r}

sessionInfo()

```


